{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "fa5b70d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "\n",
    "class CustomImageDataset(Dataset):\n",
    "    def __init__(self, root_dir, transform=None):\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.image_paths = []\n",
    "        self.labels = []\n",
    "\n",
    "        # Recorrer directorios\n",
    "        for class_name in sorted(os.listdir(root_dir)):\n",
    "            class_path = os.path.join(root_dir, class_name)\n",
    "            if os.path.isdir(class_path):\n",
    "                label = class_name  # Obtener etiqueta de la carpeta\n",
    "                for img_file in os.listdir(class_path):\n",
    "                    self.image_paths.append(os.path.join(class_path, img_file))\n",
    "                    self.labels.append(label)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.image_paths[idx]\n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "        label = self.labels[idx]\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image,label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "65d24151",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training images: 209\n",
      "['mvtec_anomaly_detection/bottle/train/good/204.png', 'mvtec_anomaly_detection/bottle/train/good/091.png', 'mvtec_anomaly_detection/bottle/train/good/078.png', 'mvtec_anomaly_detection/bottle/train/good/147.png', 'mvtec_anomaly_detection/bottle/train/good/135.png']\n",
      "Total test images: 83\n",
      "['mvtec_anomaly_detection/bottle/test/good/003.png', 'mvtec_anomaly_detection/bottle/test/good/009.png', 'mvtec_anomaly_detection/bottle/test/good/006.png', 'mvtec_anomaly_detection/bottle/test/good/013.png', 'mvtec_anomaly_detection/bottle/test/good/016.png', 'mvtec_anomaly_detection/bottle/test/good/012.png', 'mvtec_anomaly_detection/bottle/test/good/002.png', 'mvtec_anomaly_detection/bottle/test/good/018.png', 'mvtec_anomaly_detection/bottle/test/good/000.png', 'mvtec_anomaly_detection/bottle/test/good/005.png', 'mvtec_anomaly_detection/bottle/test/good/001.png', 'mvtec_anomaly_detection/bottle/test/good/008.png', 'mvtec_anomaly_detection/bottle/test/good/015.png']\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "# Entrenamiento (solo 'good')\n",
    "dir='mvtec_anomaly_detection/bottle/train'\n",
    "train_dataset = CustomImageDataset(dir,transform=transform)\n",
    "\n",
    "print(f\"Total training images: {len(train_dataset)}\")\n",
    "print(train_dataset.image_paths[:5])  # Muestra las primeras 5 imágenes\n",
    "\n",
    "# Prueba (con defectos y 'good')\n",
    "test_dataset = CustomImageDataset('mvtec_anomaly_detection/bottle/test', transform=transform)\n",
    "\n",
    "print(f\"Total test images: {len(test_dataset)}\")\n",
    "print(test_dataset.image_paths[70:])  # Muestra las primeras 5 imágenes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "cad8fcb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 83/83 [00:04<00:00, 19.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ Imágenes exportadas en: export_test/imagenes\n",
      "✅ Etiquetas guardadas en: export_test/etiquetas.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import csv\n",
    "from torchvision.utils import save_image\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Dataset a exportar\n",
    "dataset = test_dataset  # o train_dataset\n",
    "\n",
    "# Directorios de salida\n",
    "output_dir = \"export_test\"\n",
    "img_dir = os.path.join(output_dir, \"imagenes\")\n",
    "csv_path = os.path.join(output_dir, \"etiquetas.csv\")\n",
    "\n",
    "# Crear carpetas\n",
    "os.makedirs(img_dir, exist_ok=True)\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Crear CSV\n",
    "with open(csv_path, 'w', newline='') as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow(['filename', 'label'])\n",
    "\n",
    "    for idx, (img, label) in enumerate(tqdm(dataset)):\n",
    "        filename = f\"test_img_{idx:05d}.png\"\n",
    "        save_path = os.path.join(img_dir, filename)\n",
    "\n",
    "        # Guardar imagen\n",
    "        save_image(img, save_path)\n",
    "\n",
    "        # Escribir en el CSV\n",
    "        writer.writerow([filename, label])\n",
    "\n",
    "print(f\"\\n✅ Imágenes exportadas en: {img_dir}\")\n",
    "print(f\"✅ Etiquetas guardadas en: {csv_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "11f8ae82",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 209/209 [00:10<00:00, 19.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ Imágenes exportadas en: export_train/imagenes\n",
      "✅ Etiquetas guardadas en: export_train/etiquetas.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import csv\n",
    "from torchvision.utils import save_image\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Dataset a exportar\n",
    "dataset = train_dataset  # o train_dataset\n",
    "\n",
    "# Directorios de salida\n",
    "output_dir = \"export_train\"\n",
    "img_dir = os.path.join(output_dir, \"imagenes\")\n",
    "csv_path = os.path.join(output_dir, \"etiquetas.csv\")\n",
    "\n",
    "# Crear carpetas\n",
    "os.makedirs(img_dir, exist_ok=True)\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Crear CSV\n",
    "with open(csv_path, 'w', newline='') as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow(['filename', 'label'])\n",
    "\n",
    "    for idx, (img, label) in enumerate(tqdm(dataset)):\n",
    "        filename = f\"train_img_{idx:05d}.png\"\n",
    "        save_path = os.path.join(img_dir, filename)\n",
    "\n",
    "        # Guardar imagen\n",
    "        save_image(img, save_path)\n",
    "\n",
    "        # Escribir en el CSV\n",
    "        writer.writerow([filename, label])\n",
    "\n",
    "print(f\"\\n✅ Imágenes exportadas en: {img_dir}\")\n",
    "print(f\"✅ Etiquetas guardadas en: {csv_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "86046ffa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Archivo combinado guardado en: imagenes_reales/dataset_labels.csv\n",
      "\n",
      "Total de imágenes: 292\n",
      "Imágenes normales (label=0): 229 (78.42%)\n",
      "Imágenes anómalas (label=1): 63 (21.58%)\n",
      "\n",
      "Imágenes anómalas:\n",
      "['test_img_00000.png', 'test_img_00001.png', 'test_img_00002.png', 'test_img_00003.png', 'test_img_00004.png', 'test_img_00005.png', 'test_img_00006.png', 'test_img_00007.png', 'test_img_00008.png', 'test_img_00009.png', 'test_img_00010.png', 'test_img_00011.png', 'test_img_00012.png', 'test_img_00013.png', 'test_img_00014.png', 'test_img_00015.png', 'test_img_00016.png', 'test_img_00017.png', 'test_img_00018.png', 'test_img_00019.png', 'test_img_00020.png', 'test_img_00021.png', 'test_img_00022.png', 'test_img_00023.png', 'test_img_00024.png', 'test_img_00025.png', 'test_img_00026.png', 'test_img_00027.png', 'test_img_00028.png', 'test_img_00029.png', 'test_img_00030.png', 'test_img_00031.png', 'test_img_00032.png', 'test_img_00033.png', 'test_img_00034.png', 'test_img_00035.png', 'test_img_00036.png', 'test_img_00037.png', 'test_img_00038.png', 'test_img_00039.png', 'test_img_00040.png', 'test_img_00041.png', 'test_img_00042.png', 'test_img_00043.png', 'test_img_00044.png', 'test_img_00045.png', 'test_img_00046.png', 'test_img_00047.png', 'test_img_00048.png', 'test_img_00049.png', 'test_img_00050.png', 'test_img_00051.png', 'test_img_00052.png', 'test_img_00053.png', 'test_img_00054.png', 'test_img_00055.png', 'test_img_00056.png', 'test_img_00057.png', 'test_img_00058.png', 'test_img_00059.png', 'test_img_00060.png', 'test_img_00061.png', 'test_img_00062.png']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Cargar etiquetas de train y test\n",
    "df_train = pd.read_csv(\"export_train/etiquetas.csv\")\n",
    "df_test = pd.read_csv(\"export_test/etiquetas.csv\")\n",
    "\n",
    "# Unir ambos datasets\n",
    "df = pd.concat([df_train, df_test], ignore_index=True)\n",
    "\n",
    "# Codificar etiquetas: 'good' → 0, otros → 1\n",
    "df[\"label\"] = df[\"label\"].apply(lambda x: 0 if x == \"good\" else 1)\n",
    "df.to_csv(\"imagenes_reales/dataset_labels.csv\", index=False)\n",
    "print(\"✅ Archivo combinado guardado en: imagenes_reales/dataset_labels.csv\")\n",
    "\n",
    "# -------------------------\n",
    "# Análisis del dataset\n",
    "# -------------------------\n",
    "# Cargar el dataset fusionado\n",
    "df = pd.read_csv(\"imagenes_reales/dataset_labels.csv\")\n",
    "\n",
    "# Cálculos\n",
    "normal_count = df[df[\"label\"] == 0].shape[0]\n",
    "anomalous_count = df[df[\"label\"] == 1].shape[0]\n",
    "total_count = len(df)\n",
    "\n",
    "normal_percentage = (normal_count / total_count) * 100\n",
    "anomalous_percentage = (anomalous_count / total_count) * 100\n",
    "\n",
    "# Obtener nombres de imágenes anómalas\n",
    "anomalous_filenames = df[df[\"label\"] == 1][\"filename\"].tolist()\n",
    "\n",
    "# Mostrar resultados\n",
    "print(f\"\\nTotal de imágenes: {total_count}\")\n",
    "print(f\"Imágenes normales (label=0): {normal_count} ({normal_percentage:.2f}%)\")\n",
    "print(f\"Imágenes anómalas (label=1): {anomalous_count} ({anomalous_percentage:.2f}%)\")\n",
    "print(\"\\nImágenes anómalas:\")\n",
    "print(anomalous_filenames)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f07ae10",
   "metadata": {},
   "source": [
    "FLATTEN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "c6ec5f27",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def flatten_image(image_path):\n",
    "   img = Image.open(image_path) \n",
    "   img_array = np.array(img)    # Convertir de una imaegn PIL a un array para luego hacer el flatten\n",
    "   flattened_image = img_array.flatten()\n",
    "   return flattened_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "7dfe7203",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([292, 196608])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "flattened_images = []\n",
    "labels = []\n",
    "\n",
    "for _, row in df.iterrows():\n",
    "    image_path = row['filename']\n",
    "    flattened_image = flatten_image(f\"imagenes_reales/{image_path}\")  # debe devolver un tensor\n",
    "    flattened_tensor = torch.from_numpy(flattened_image)\n",
    "    flattened_images.append(flattened_tensor)\n",
    "    labels.append(row['label'])\n",
    "\n",
    "# Convertimos la lista de tensores a un solo tensor\n",
    "image_tensor = torch.stack(flattened_images)  # shape: [N, ...]\n",
    "\n",
    "\n",
    "print(image_tensor.shape)  # Verificar la forma del tensor de imágenes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "935408cd",
   "metadata": {},
   "source": [
    "Modelo Preentrenado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "075a0e7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      "  (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (4): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (5): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (3): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (6): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (3): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (4): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (5): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (7): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (8): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision import models\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "# Cargar modelo preentrenado ResNet-50\n",
    "model = models.resnet50(pretrained=True)\n",
    "\n",
    "# Eliminar la capa de clasificación (fc)\n",
    "model = torch.nn.Sequential(*list(model.children())[:-1])\n",
    "\n",
    "# Ver la arquitectura resultante\n",
    "print(model)\n",
    "\n",
    "model.eval()  # Poner en modo evaluación\n",
    "\n",
    "# Transformaciones necesarias para ResNet-50\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  # Redimensionar a 224x224\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # se usan estos valores por que son los que se usaron\n",
    "                                                                                 # el entrenamiento de la resnet\n",
    "])\n",
    "\n",
    "# Lista para almacenar los embeddings\n",
    "embeddings = []\n",
    "\n",
    "# Iterar sobre las imágenes del dataset\n",
    "for index, row in df.iterrows():\n",
    "    image_path = row['filename']\n",
    "    image = Image.open(f\"imagenes_reales/{image_path}\")\n",
    "    image = transform(image)\n",
    "    image = image.unsqueeze(0)   #añadir una dimension mas para el batch\n",
    "\n",
    "    with torch.no_grad():      #deshabilita el calculo del gradiente\n",
    "        embedding = model(image)\n",
    "    embedding = embedding.squeeze().cpu().numpy()   #squeeze: elimina dimensiones de tamaño 1 del tensor\n",
    "                                                    #cpu: mueve el tensor embedding a la gpu\n",
    "                                                    #numpy: convierte a un array de numpy\n",
    "    embeddings.append(embedding)\n",
    "\n",
    "#Crear un DataFrame con los embeddings\n",
    "embeddings_df = pd.DataFrame(embeddings)\n",
    "embeddings_df['label'] = df['label']  # Agregar las etiquetas al nuevo dataset\n",
    "\n",
    "# Guardar el DataFrame con los embeddings\n",
    "embeddings_df.to_csv(\"embeddings.csv\", index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6148eeb",
   "metadata": {},
   "source": [
    "Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "dbb5dc8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method Module.state_dict of Autoencoder(\n",
      "  (encoder): Sequential(\n",
      "    (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (3): Conv2d(32, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (4): ReLU()\n",
      "    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (6): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (7): ReLU()\n",
      "    (8): MaxPool2d(kernel_size=7, stride=7, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (decoder): Sequential(\n",
      "    (0): ConvTranspose2d(16, 16, kernel_size=(7, 7), stride=(7, 7))\n",
      "    (1): ReLU()\n",
      "    (2): ConvTranspose2d(16, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
      "    (3): ReLU()\n",
      "    (4): ConvTranspose2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
      "    (5): ReLU()\n",
      "    (6): ConvTranspose2d(32, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (7): Sigmoid()\n",
      "  )\n",
      ")>\n",
      "Dimensión final de salida: torch.Size([1, 1, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import ast\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# Definir el Autoencoder con espacio latente 16x1x1\n",
    "class Autoencoder(nn.Module):\n",
    "    def __init__(self, input_channels=3, output_channels=1):\n",
    "        super(Autoencoder, self).__init__()\n",
    "\n",
    "        # Encoder (Reducir hasta 16x1x1)\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(input_channels, 32, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "\n",
    "            nn.Conv2d(32, 16, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "\n",
    "            nn.Conv2d(16, 16, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=7, stride=7)\n",
    "        )\n",
    "\n",
    "        # Decoder (Expandir desde 16x1x1 hasta 1x28x28)\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.ConvTranspose2d(16, 16, kernel_size=7, stride=7),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.ConvTranspose2d(16, 16, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.ConvTranspose2d(16, 32, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.ConvTranspose2d(32, output_channels, kernel_size=3, stride=1, padding=1),\n",
    "            nn.Sigmoid()  # Normalizar salida [0,1]\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        encoded = self.encoder(x)\n",
    "\n",
    "        decoded = self.decoder(encoded)\n",
    "        return decoded\n",
    "\n",
    "# Prueba con un tensor de entrada (batch_size=1, canal=1, 28x28)\n",
    "x_test = torch.randn(1, 3, 28, 28)\n",
    "\n",
    "# Inicializar modelo y obtener salida\n",
    "model = Autoencoder()\n",
    "output = model(x_test)\n",
    "print(model.state_dict)\n",
    "# Imprimir dimensiones de salida\n",
    "print(\"Dimensión final de salida:\", output.shape)  # Esperado: (1, 1, 28, 28)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "c31a6070",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Entrenando Autoencoder en STL10...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Época 1/10:   0%|          | 0/40 [00:00<?, ?it/s]/opt/python/3.10/lib/python3.10/site-packages/torch/nn/modules/loss.py:538: UserWarning: Using a target size (torch.Size([128, 3, 28, 28])) that is different to the input size (torch.Size([128, 1, 28, 28])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "Época 1/10:  95%|█████████▌| 38/40 [00:03<00:00, 11.68it/s]/opt/python/3.10/lib/python3.10/site-packages/torch/nn/modules/loss.py:538: UserWarning: Using a target size (torch.Size([8, 3, 28, 28])) that is different to the input size (torch.Size([8, 1, 28, 28])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "Época 1/10: 100%|██████████| 40/40 [00:03<00:00, 11.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Época [1/10], Pérdida: 0.056128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Época 2/10: 100%|██████████| 40/40 [00:03<00:00, 11.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Época [2/10], Pérdida: 0.044193\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Época 3/10: 100%|██████████| 40/40 [00:03<00:00, 12.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Época [3/10], Pérdida: 0.036190\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Época 4/10: 100%|██████████| 40/40 [00:03<00:00, 12.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Época [4/10], Pérdida: 0.032786\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Época 5/10: 100%|██████████| 40/40 [00:03<00:00, 12.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Época [5/10], Pérdida: 0.031077\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Época 6/10: 100%|██████████| 40/40 [00:03<00:00, 12.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Época [6/10], Pérdida: 0.030069\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Época 7/10: 100%|██████████| 40/40 [00:03<00:00, 12.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Época [7/10], Pérdida: 0.029037\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Época 8/10: 100%|██████████| 40/40 [00:03<00:00, 12.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Época [8/10], Pérdida: 0.028558\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Época 9/10: 100%|██████████| 40/40 [00:03<00:00, 12.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Época [9/10], Pérdida: 0.028053\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Época 10/10: 100%|██████████| 40/40 [00:03<00:00, 12.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Época [10/10], Pérdida: 0.027759\n",
      "Modelo guardado en autoencoder_mnist.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Configurar dispositivo\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Hiperparámetros\n",
    "batch_size = 128\n",
    "learning_rate = 0.001\n",
    "num_epochs = 10\n",
    "\n",
    "# Transformaciones para MNIST\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Resize((28,28)),\n",
    "])\n",
    "\n",
    "# Cargar MNIST\n",
    "train_dataset = datasets.STL10(root='./data', split='train',        # Puedes usar 'train+unlabeled' también\n",
    "    download=True,\n",
    "    transform=transform)\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)   # se crea un iterador para entrenar\n",
    "\n",
    "# Crear instancia del Autoencoder\n",
    "autoencoder = Autoencoder().to(device)\n",
    "\n",
    "# Definir función de pérdida y optimizador\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(autoencoder.parameters(), lr=learning_rate)\n",
    "\n",
    "# Entrenar el Autoencoder\n",
    "print(\"Entrenando Autoencoder en STL10...\")\n",
    "for epoch in range(num_epochs):\n",
    "    running_loss = 0.0\n",
    "    for images, _ in tqdm(train_loader, desc=f\"Época {epoch+1}/{num_epochs}\"):  #se itera sobre los batches utilizando el iterador antes mencionado\n",
    "        images = images.to(device)\n",
    "\n",
    "        # Forward\n",
    "        outputs = autoencoder(images)      # se obtiene la salida del autonencoder\n",
    "        loss = criterion(outputs, images)  # Comparar salida con entrada\n",
    "\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()             #se ponen a cero los gradientes acumulados de los parametros\n",
    "                                          # del modelo en el optimizador\n",
    "        loss.backward()                   # se calcula el gradiente con respecto a los parámetros del modelo\n",
    "        optimizer.step()                  # se actualizan los pesos del modelo utilizando el optimizador\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    print(f\"Época [{epoch+1}/{num_epochs}], Pérdida: {running_loss / len(train_loader):.6f}\")\n",
    "\n",
    "# Guardar modelo entrenado\n",
    "model_path = \"autoencoder_mnist.pth\"\n",
    "torch.save(autoencoder.state_dict(), model_path)\n",
    "print(f\"Modelo guardado en {model_path}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "d015e1f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/tmp/ipykernel_16969/3959307350.py:6: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extrayendo embeddings...\n",
      "Embeddings guardados en dataset_embeddings_encoder.csv\n"
     ]
    }
   ],
   "source": [
    "# ==========================\n",
    "# Cargar modelo y evaluar solo el Encoder\n",
    "# ==========================\n",
    "\n",
    "model = Autoencoder()\n",
    "model.load_state_dict(torch.load(model_path))\n",
    "model.eval()  # Modo evaluación\n",
    "\n",
    "# Extraer solo el encoder\n",
    "encoder = autoencoder.encoder\n",
    "encoder.to(device)\n",
    "encoder.eval()\n",
    "\n",
    "# Transformaciones para imágenes externas\n",
    "transform = transforms.Compose([  # Asegurar que tenga 1 canal\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Resize((28,28)),\n",
    "])\n",
    "\n",
    "# Lista para almacenar los embeddings\n",
    "embeddings = []\n",
    "\n",
    "# Iterar sobre las imágenes del dataset\n",
    "for index, row in df.iterrows():\n",
    "    image_path = row['filename']\n",
    "    image = Image.open(f\"imagenes_reales/{image_path}\")  # Convertir a escala de grises\n",
    "    image = transform(image)\n",
    "    image = image.unsqueeze(0).to(device)   #añadir una dimension mas para el batch\n",
    "\n",
    "    with torch.no_grad():      #deshabilita el calculo del gradiente\n",
    "        embedding = encoder(image)\n",
    "    embedding = embedding.squeeze().cpu().numpy()   #squeeze: elimina dimensiones de tamaño 1 del tensor\n",
    "                                                    #cpu: mueve el tensor embedding a la gpu\n",
    "                                                    #numpy: convierte a un array de numpy\n",
    "    embeddings.append(embedding)\n",
    "\n",
    "# Procesar todas las imágenes en el dataset externo\n",
    "print(\"Extrayendo embeddings...\")\n",
    "\n",
    "\n",
    "# Convertir a DataFrame y guardar\n",
    "embeddings_df = pd.DataFrame(embeddings)\n",
    "embeddings_df['label'] = df['label']  # Agregar las etiquetas al nuevo dataset)\n",
    "\n",
    "# Guardar en archivo CSV\n",
    "output_file = \"dataset_embeddings_encoder.csv\"\n",
    "embeddings_df.to_csv(output_file, index=False)\n",
    "\n",
    "print(f\"Embeddings guardados en {output_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f280716",
   "metadata": {},
   "source": [
    "RESNET AUTOENCODER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "51dc9190",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/python/3.10/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/opt/python/3.10/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method Module.state_dict of ResNetAutoencoder(\n",
      "  (encoder): Sequential(\n",
      "    (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "    (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "    (4): Sequential(\n",
      "      (0): Bottleneck(\n",
      "        (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (downsample): Sequential(\n",
      "          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): Bottleneck(\n",
      "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (2): Bottleneck(\n",
      "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (5): Sequential(\n",
      "      (0): Bottleneck(\n",
      "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (downsample): Sequential(\n",
      "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): Bottleneck(\n",
      "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (2): Bottleneck(\n",
      "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (3): Bottleneck(\n",
      "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (6): Sequential(\n",
      "      (0): Bottleneck(\n",
      "        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (downsample): Sequential(\n",
      "          (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): Bottleneck(\n",
      "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (2): Bottleneck(\n",
      "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (3): Bottleneck(\n",
      "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (4): Bottleneck(\n",
      "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (5): Bottleneck(\n",
      "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (7): Sequential(\n",
      "      (0): Bottleneck(\n",
      "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (downsample): Sequential(\n",
      "          (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "          (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): Bottleneck(\n",
      "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (2): Bottleneck(\n",
      "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (8): Conv2d(2048, 2048, kernel_size=(4, 4), stride=(1, 1))\n",
      "    (9): Flatten(start_dim=1, end_dim=-1)\n",
      "    (10): Linear(in_features=2048, out_features=1024, bias=True)\n",
      "    (11): ReLU()\n",
      "    (12): Dropout(p=0.2, inplace=False)\n",
      "    (13): Linear(in_features=1024, out_features=256, bias=True)\n",
      "    (14): ReLU()\n",
      "    (15): Dropout(p=0.2, inplace=False)\n",
      "    (16): Linear(in_features=256, out_features=64, bias=True)\n",
      "  )\n",
      "  (decoder): Sequential(\n",
      "    (0): Linear(in_features=64, out_features=256, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=256, out_features=2048, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): ViewLayer()\n",
      "    (5): ConvTranspose2d(2048, 2048, kernel_size=(4, 4), stride=(1, 1))\n",
      "    (6): ReLU()\n",
      "    (7): ConvTranspose2d(2048, 1024, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "    (8): ReLU()\n",
      "    (9): ConvTranspose2d(1024, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "    (10): ReLU()\n",
      "    (11): ConvTranspose2d(512, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "    (12): ReLU()\n",
      "    (13): ConvTranspose2d(256, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "    (14): ReLU()\n",
      "    (15): ConvTranspose2d(64, 3, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "    (16): Sigmoid()\n",
      "  )\n",
      ")>\n",
      "Dimensión final de salida: torch.Size([1, 3, 128, 128])\n",
      "Dimensión final de salida encoder: torch.Size([1, 64])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "\n",
    "\n",
    "class ViewLayer(nn.Module):\n",
    "    def __init__(self, shape):\n",
    "        super().__init__()\n",
    "        self.shape = shape\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x.view(x.size(0), *self.shape)\n",
    "\n",
    "class ResNetAutoencoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        resnet = models.resnet50(pretrained=True)\n",
    "\n",
    "        # Compacto: todas las capas convolucionales hasta layer4\n",
    "        self.encoder = nn.Sequential(*list(resnet.children())[:8],\n",
    "                                     nn.Conv2d(2048, 2048, kernel_size=4),\n",
    "                                     nn.Flatten(),\n",
    "                                     nn.Linear(2048, 1024),\n",
    "                                        nn.ReLU(),\n",
    "                                        nn.Dropout(0.2),\n",
    "                                     nn.Linear(1024, 256),\n",
    "                                        nn.ReLU(),\n",
    "                                        nn.Dropout(0.2),\n",
    "                                        nn.Linear(256, 64))\n",
    "\n",
    "\n",
    "\n",
    "        # Decoder: invertir el proceso usando conv transpuestas\n",
    "        self.decoder = nn.Sequential(\n",
    "            # Primero, expandimos [B, 64] → [B, 256]\n",
    "            nn.Linear(64, 256),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            # Expandimos más: [B, 256] → [B, 2048]\n",
    "            nn.Linear(256, 2048),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            # Ahora lo preparamos para reshape: [B, 2048] → [B, 2048, 1, 1]\n",
    "            ViewLayer((2048, 1, 1)),  # capa auxiliar para reshaping\n",
    "            nn.ConvTranspose2d(2048, 2048, kernel_size=4),  # [B, 2048, 4, 4]\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(2048, 1024, kernel_size=4, stride=2, padding=1),  # -> [B, 1024, 8, 8]\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(1024, 512, kernel_size=4, stride=2, padding=1),   # -> [B, 512, 16, 16]\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(512, 256, kernel_size=4, stride=2, padding=1),    # -> [B, 256, 32, 32]\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(256, 64, kernel_size=4, stride=2, padding=1),     # -> [B, 64, 64, 64]\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(64, 3, kernel_size=4, stride=2, padding=1),       # -> [B, 3, 128, 128]\n",
    "            nn.Sigmoid()  # para imágenes normalizadas en [0,1]\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x)\n",
    "        return x\n",
    "\n",
    "# Prueba con un tensor de entrada (batch_size=1, canal=3, 28x28)\n",
    "x_test = torch.randn(1, 3, 128, 128)\n",
    "\n",
    "# Inicializar modelo y obtener salida\n",
    "model = ResNetAutoencoder()\n",
    "output = model(x_test)\n",
    "print(model.state_dict)\n",
    "output_encoder=model.encoder(x_test)\n",
    "# Imprimir dimensiones de salida\n",
    "print(\"Dimensión final de salida:\", output.shape)  # Esperado: (1, 1, 28, 28)\n",
    "print(\"Dimensión final de salida encoder:\", output_encoder.shape)  # Esperado: (1, 1, 28, 28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcf01947",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)\n",
      "Cell \u001b[0;32mIn[147], line 16\u001b[0m\n",
      "\u001b[1;32m     10\u001b[0m transform \u001b[38;5;241m=\u001b[39m transforms\u001b[38;5;241m.\u001b[39mCompose([\n",
      "\u001b[1;32m     11\u001b[0m     transforms\u001b[38;5;241m.\u001b[39mToTensor(),\n",
      "\u001b[1;32m     12\u001b[0m     transforms\u001b[38;5;241m.\u001b[39mResize((\u001b[38;5;241m128\u001b[39m,\u001b[38;5;241m128\u001b[39m)),\n",
      "\u001b[1;32m     13\u001b[0m ])\n",
      "\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# Cargar MNIST\u001b[39;00m\n",
      "\u001b[0;32m---> 16\u001b[0m train_dataset \u001b[38;5;241m=\u001b[39m \u001b[43mdatasets\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mSTL10\u001b[49m\u001b[43m(\u001b[49m\u001b[43mroot\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m./data\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msplit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtrain+unlabeled\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Puedes usar 'train+unlabeled' también\u001b[39;49;00m\n",
      "\u001b[1;32m     17\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdownload\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m     18\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtransform\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;32m     19\u001b[0m train_loader \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mDataLoader(train_dataset, batch_size\u001b[38;5;241m=\u001b[39mbatch_size, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)   \u001b[38;5;66;03m# se crea un iterador para entrenar\u001b[39;00m\n",
      "\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m# Crear instancia del Autoencoder\u001b[39;00m\n",
      "\n",
      "File \u001b[0;32m/opt/python/3.10/lib/python3.10/site-packages/torchvision/datasets/stl10.py:76\u001b[0m, in \u001b[0;36mSTL10.__init__\u001b[0;34m(self, root, split, folds, transform, target_transform, download)\u001b[0m\n",
      "\u001b[1;32m     74\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlabels \u001b[38;5;241m=\u001b[39m cast(np\u001b[38;5;241m.\u001b[39mndarray, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlabels)\n",
      "\u001b[1;32m     75\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__load_folds(folds)\n",
      "\u001b[0;32m---> 76\u001b[0m unlabeled_data, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__loadfile\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_list\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;32m     77\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mconcatenate((\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata, unlabeled_data))\n",
      "\u001b[1;32m     78\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlabels \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mconcatenate((\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlabels, np\u001b[38;5;241m.\u001b[39masarray([\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m*\u001b[39m unlabeled_data\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m])))\n",
      "\n",
      "File \u001b[0;32m/opt/python/3.10/lib/python3.10/site-packages/torchvision/datasets/stl10.py:142\u001b[0m, in \u001b[0;36mSTL10.__loadfile\u001b[0;34m(self, data_file, labels_file)\u001b[0m\n",
      "\u001b[1;32m    139\u001b[0m path_to_data \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mroot, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbase_folder, data_file)\n",
      "\u001b[1;32m    140\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(path_to_data, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n",
      "\u001b[1;32m    141\u001b[0m     \u001b[38;5;66;03m# read whole file in uint8 chunks\u001b[39;00m\n",
      "\u001b[0;32m--> 142\u001b[0m     everything \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfromfile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43muint8\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;32m    143\u001b[0m     images \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mreshape(everything, (\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m96\u001b[39m, \u001b[38;5;241m96\u001b[39m))\n",
      "\u001b[1;32m    144\u001b[0m     images \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mtranspose(images, (\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m2\u001b[39m))\n",
      "\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Configurar dispositivo\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Hiperparámetros\n",
    "batch_size = 128\n",
    "learning_rate = 0.001\n",
    "num_epochs = 10\n",
    "\n",
    "# Transformaciones para MNIST\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Resize((128,128)),\n",
    "])\n",
    "\n",
    "# Cargar MNIST\n",
    "train_dataset = datasets.STL10(root='./data', split='train',        # Puedes usar 'train+unlabeled' también\n",
    "    download=True,\n",
    "    transform=transform)\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)   # se crea un iterador para entrenar\n",
    "\n",
    "# Crear instancia del Autoencoder\n",
    "autoencoder = ResNetAutoencoder().to(device)\n",
    "\n",
    "# Definir función de pérdida y optimizador\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(autoencoder.parameters(), lr=learning_rate)\n",
    "\n",
    "# Entrenar el Autoencoder\n",
    "print(\"Entrenando Autoencoder en STL10...\")\n",
    "for epoch in range(num_epochs):\n",
    "    running_loss = 0.0\n",
    "    for images, _ in tqdm(train_loader, desc=f\"Época {epoch+1}/{num_epochs}\"):  #se itera sobre los batches utilizando el iterador antes mencionado\n",
    "        images = images.to(device)\n",
    "\n",
    "        # Forward\n",
    "        outputs = autoencoder(images)      # se obtiene la salida del autonencoder\n",
    "        loss = criterion(outputs, images)  # Comparar salida con entrada\n",
    "\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()             #se ponen a cero los gradientes acumulados de los parametros\n",
    "                                          # del modelo en el optimizador\n",
    "        loss.backward()                   # se calcula el gradiente con respecto a los parámetros del modelo\n",
    "        optimizer.step()                  # se actualizan los pesos del modelo utilizando el optimizador\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    print(f\"Época [{epoch+1}/{num_epochs}], Pérdida: {running_loss / len(train_loader):.6f}\")\n",
    "\n",
    "# Guardar modelo entrenado\n",
    "model_path = \"autoencoder_resnet.pth\"\n",
    "torch.save(autoencoder.state_dict(), model_path)\n",
    "print(f\"Modelo guardado en {model_path}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "e139921c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/python/3.10/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/opt/python/3.10/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "/var/tmp/ipykernel_16969/2510974994.py:7: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(\"autoencoder_resnet.pth\"))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extrayendo embeddings...\n",
      "Embeddings guardados en dataset_embeddings_encoder_resnet.csv\n"
     ]
    }
   ],
   "source": [
    "# ==========================\n",
    "# Cargar modelo y evaluar solo el Encoder\n",
    "# ==========================\n",
    "\n",
    "# Cargar el modelo entrenado\n",
    "model = ResNetAutoencoder()\n",
    "model.load_state_dict(torch.load(\"autoencoder_resnet.pth\"))\n",
    "model.eval()  # Modo evaluación\n",
    "\n",
    "# Extraer solo el encoder\n",
    "encoder = model.encoder\n",
    "encoder.to(device)\n",
    "encoder.eval()\n",
    "\n",
    "# Transformaciones para imágenes externas\n",
    "transform = transforms.Compose([  # Asegurar que tenga 1 canal\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Resize((128,128)),\n",
    "    transforms.Lambda(lambda x: x.expand(3, -1, -1))  # convertir 1 canal → 3 canales\n",
    "])\n",
    "\n",
    "# Lista para almacenar los embeddings\n",
    "embeddings = []\n",
    "\n",
    "# Iterar sobre las imágenes del dataset\n",
    "for index, row in df.iterrows():\n",
    "    image_path = row['filename']\n",
    "    image = Image.open(f\"imagenes_reales/{image_path}\")\n",
    "    image = transform(image)\n",
    "    image = image.unsqueeze(0).to(device)   #añadir una dimension mas para el batch\n",
    "\n",
    "    with torch.no_grad():      #deshabilita el calculo del gradiente\n",
    "        embedding = encoder(image)\n",
    "    embedding = embedding.squeeze().cpu().numpy()   #squeeze: elimina dimensiones de tamaño 1 del tensor\n",
    "                                                    #cpu: mueve el tensor embedding a la gpu\n",
    "                                                    #numpy: convierte a un array de numpy\n",
    "    embeddings.append(embedding)\n",
    "\n",
    "# Procesar todas las imágenes en el dataset externo\n",
    "print(\"Extrayendo embeddings...\")\n",
    "\n",
    "\n",
    "# Convertir a DataFrame y guardar\n",
    "embeddings_df = pd.DataFrame(embeddings)\n",
    "embeddings_df['label'] = df['label']  # Agregar las etiquetas al nuevo dataset)\n",
    "\n",
    "# Guardar en archivo CSV\n",
    "output_file = \"dataset_embeddings_encoder_resnet.csv\"\n",
    "embeddings_df.to_csv(output_file, index=False)\n",
    "\n",
    "print(f\"Embeddings guardados en {output_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eb0687e",
   "metadata": {},
   "source": [
    "DISTRIBUCION DE LOS DATOS CON CENTROIDE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "4cdc80f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def AnomalyDetector(file_path, k=3):  # k controla qué tan lejos consideramos anómalo\n",
    "    df = pd.read_csv(file_path)\n",
    "\n",
    "    embedding_columns = df.columns[:-1]  # nombres de columnas excepto la última\n",
    "    embeddings = df[embedding_columns].values\n",
    "\n",
    "    # Calcular el centroide\n",
    "    centroid = np.mean(embeddings, axis=0)\n",
    "    distances = np.linalg.norm(embeddings - centroid, axis=1)\n",
    "\n",
    "    # Calcular la media y desviación estándar de las distancias\n",
    "    mean_dist = np.mean(distances)\n",
    "    std_dist = np.std(distances)\n",
    "\n",
    "    # Definir umbral basado en k desviaciones estándar\n",
    "    threshold = mean_dist + k * std_dist\n",
    "\n",
    "    # Identificar anomalías\n",
    "    anomalous_examples = df.loc[distances > threshold]\n",
    "\n",
    "    return anomalous_examples\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "f970f218",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anomaly Detector\n",
      "            0         1         2         3         4         5         6  \\\n",
      "2    1.138372  0.474673  0.076546  0.025930  1.464019  0.825359  0.570955   \n",
      "12   0.943661  0.864050  0.040693  0.001843  1.591970  0.630615  0.596591   \n",
      "22   1.237791  0.727628  0.093860  0.046641  1.735232  0.540565  0.719597   \n",
      "25   0.942185  0.699878  0.330590  0.016602  1.539579  0.389360  0.932401   \n",
      "48   1.024678  0.540794  0.227426  0.005122  1.402829  0.419207  0.703321   \n",
      "74   0.925889  0.602573  0.190677  0.016207  1.304960  0.423691  0.759735   \n",
      "75   1.033656  0.597987  0.192873  0.006274  1.343840  0.358058  0.689633   \n",
      "85   1.005027  0.630002  0.228996  0.011468  1.362785  0.407044  0.849415   \n",
      "102  0.781428  0.724238  0.282848  0.018604  1.465149  0.528963  0.589808   \n",
      "106  0.818515  0.536316  0.197660  0.000691  1.279285  0.502947  0.689971   \n",
      "130  1.003127  0.634560  0.340014  0.018634  1.474930  0.353921  0.769650   \n",
      "138  0.984462  0.983883  0.259868  0.003474  1.491165  0.631300  0.742661   \n",
      "145  0.937164  0.628620  0.210636  0.008240  1.400120  0.408125  0.874637   \n",
      "150  1.101937  1.005025  0.242879  0.020484  1.388120  0.522934  0.776647   \n",
      "174  0.970731  0.709839  0.255402  0.012238  1.402524  0.410292  0.665126   \n",
      "181  0.884935  0.587189  0.221686  0.003140  1.439324  0.396842  0.752372   \n",
      "190  0.870158  0.637994  0.227336  0.009737  1.345759  0.351627  0.660268   \n",
      "209  0.709227  1.225374  0.531734  0.052287  1.037283  0.813432  0.422084   \n",
      "210  0.667125  0.855499  0.083014  0.081553  1.074452  0.845796  0.208278   \n",
      "213  0.810315  0.808546  0.232287  0.072550  1.148616  0.624248  0.315404   \n",
      "214  0.768155  0.822854  0.116296  0.050538  1.291615  0.923397  0.651064   \n",
      "215  0.445632  0.797932  0.423541  0.013500  1.023762  0.595295  0.501139   \n",
      "216  0.521111  1.071002  0.378717  0.059176  0.804918  0.506765  0.410701   \n",
      "218  0.554688  0.730218  0.274354  0.050875  1.132186  0.904598  0.264826   \n",
      "219  0.614740  0.831066  0.341944  0.182056  1.052942  0.876627  0.245679   \n",
      "220  0.431201  0.960878  0.347554  0.094034  1.115819  0.961445  0.320201   \n",
      "221  0.638727  0.906015  0.253130  0.128898  1.267910  1.049916  0.413180   \n",
      "222  0.483743  1.129390  0.593156  0.069391  1.035394  0.656175  0.238385   \n",
      "223  0.631415  0.874285  0.296852  0.029270  0.930192  0.597243  0.225764   \n",
      "224  0.702645  0.744503  0.363793  0.036694  1.174328  0.903706  0.415623   \n",
      "226  0.457248  0.855174  0.228247  0.030949  0.954306  0.745100  0.488971   \n",
      "227  0.511221  0.713831  0.460841  0.052182  0.824076  0.719641  0.485532   \n",
      "228  0.685770  0.709538  0.289846  0.101654  1.167774  0.651526  0.411046   \n",
      "235  0.505905  0.524559  0.141784  0.004479  1.137519  0.737694  0.408768   \n",
      "237  0.616838  0.570787  0.103649  0.025939  1.075127  1.030203  0.517512   \n",
      "238  0.686795  0.608126  0.233489  0.059715  1.183978  0.678585  0.486422   \n",
      "243  0.649778  0.819298  0.186273  0.014182  1.306776  0.732916  0.590593   \n",
      "244  0.755480  0.617459  0.046658  0.033221  1.243035  0.734250  0.267044   \n",
      "245  0.584761  0.597162  0.271752  0.020907  1.251160  0.743857  0.545722   \n",
      "247  0.683409  0.626004  0.240474  0.000000  1.324731  0.491712  0.659856   \n",
      "249  0.603501  0.931325  0.055147  0.067616  1.546374  1.096478  0.466691   \n",
      "250  0.858426  0.666792  0.044061  0.108718  1.530119  0.857029  0.341759   \n",
      "251  1.002467  0.325059  0.061513  0.050918  1.065610  0.337060  0.191933   \n",
      "253  1.025644  0.221742  0.098794  0.011970  1.162759  0.567238  0.411469   \n",
      "255  1.062027  0.338992  0.117000  0.031184  0.816954  0.422752  0.083516   \n",
      "257  0.786358  0.978480  0.107299  0.174404  1.369104  0.948881  0.427331   \n",
      "259  1.470095  0.963301  0.387002  0.051096  1.245868  0.542465  0.416824   \n",
      "260  1.139569  0.819109  0.053144  0.072638  1.218776  0.752935  0.156796   \n",
      "261  1.026016  0.712631  0.470252  0.128072  1.048549  0.770248  0.522505   \n",
      "262  1.082901  0.499319  0.266975  0.005267  1.365018  0.393328  0.831937   \n",
      "263  1.366882  0.837348  0.379532  0.030051  1.189948  0.408425  0.307567   \n",
      "264  1.279180  0.825328  0.164206  0.020419  1.074366  0.536247  0.342505   \n",
      "266  0.892222  0.737383  0.228041  0.063629  1.522985  0.596980  0.641731   \n",
      "267  1.278869  0.501164  0.227899  0.039319  1.171735  0.404548  0.047943   \n",
      "268  0.982641  0.358145  0.164038  0.124158  1.213055  1.367467  0.367863   \n",
      "269  1.315769  0.859706  0.131031  0.134442  1.310001  0.588366  0.220059   \n",
      "270  1.513876  0.705194  0.137677  0.012993  1.032963  0.493122  0.038035   \n",
      "271  1.358010  0.302827  0.090147  0.029914  1.255591  0.468270  0.127896   \n",
      "281  1.020354  0.706830  0.250300  0.005008  1.508329  0.600120  0.837838   \n",
      "\n",
      "            7         8         9  ...      2039      2040      2041  \\\n",
      "2    1.208107  0.972250  0.107044  ...  0.084146  0.008956  1.956424   \n",
      "12   1.294009  0.866084  0.148838  ...  0.048912  0.026708  2.070573   \n",
      "22   1.993377  0.310750  0.194692  ...  0.043821  0.090320  1.725193   \n",
      "25   2.110863  0.640893  0.342145  ...  0.089952  0.008580  1.678741   \n",
      "48   1.553875  0.623160  0.220721  ...  0.058115  0.006538  1.948670   \n",
      "74   1.576863  0.416303  0.323307  ...  0.068331  0.008932  1.817460   \n",
      "75   1.663606  0.599951  0.394788  ...  0.088103  0.037779  1.584524   \n",
      "85   1.790806  0.585213  0.408141  ...  0.058789  0.000000  1.546802   \n",
      "102  1.679019  0.685268  0.222957  ...  0.133329  0.030528  1.286433   \n",
      "106  1.719378  0.497715  0.383672  ...  0.053698  0.000000  1.727859   \n",
      "130  1.995709  0.451229  0.322301  ...  0.088421  0.001609  1.528282   \n",
      "138  2.452944  0.393938  0.473770  ...  0.062923  0.000000  1.733689   \n",
      "145  1.454235  0.543875  0.305052  ...  0.056648  0.009316  1.563498   \n",
      "150  1.975149  0.397490  0.318026  ...  0.057296  0.011805  1.718909   \n",
      "174  2.156750  0.675754  0.242195  ...  0.091986  0.010032  1.402300   \n",
      "181  1.792866  0.585002  0.307157  ...  0.051036  0.004602  1.977349   \n",
      "190  1.531950  0.699164  0.200410  ...  0.105345  0.015583  1.624770   \n",
      "209  1.720491  0.354444  0.106499  ...  0.107346  0.042004  1.004991   \n",
      "210  1.572550  0.621069  0.093106  ...  0.056910  0.054419  0.876541   \n",
      "213  1.157122  0.432193  0.100850  ...  0.079723  0.215651  1.230108   \n",
      "214  1.567333  0.715789  0.130292  ...  0.057922  0.048502  1.368177   \n",
      "215  1.799465  0.402095  0.269848  ...  0.087365  0.101685  0.920664   \n",
      "216  1.909231  0.372364  0.268928  ...  0.202981  0.062783  0.664868   \n",
      "218  1.613422  0.562453  0.169351  ...  0.102517  0.328048  0.948066   \n",
      "219  1.918795  0.407071  0.208880  ...  0.108674  0.079919  0.701086   \n",
      "220  1.354896  0.317496  0.100894  ...  0.055286  0.097185  0.769718   \n",
      "221  2.214300  0.591572  0.108865  ...  0.068129  0.043345  0.939418   \n",
      "222  1.764035  0.188783  0.126144  ...  0.201266  0.068135  0.865753   \n",
      "223  1.841485  0.326703  0.101090  ...  0.113253  0.298402  1.207057   \n",
      "224  2.011620  0.642201  0.164989  ...  0.056391  0.018464  1.054970   \n",
      "226  1.736955  0.508777  0.275013  ...  0.093356  0.051301  1.018253   \n",
      "227  1.935090  0.493758  0.214512  ...  0.121216  0.139475  0.697145   \n",
      "228  1.465636  0.426070  0.164905  ...  0.052693  0.064039  0.896562   \n",
      "235  1.399862  0.669248  0.119715  ...  0.085925  0.017023  1.228558   \n",
      "237  1.787194  0.741899  0.129386  ...  0.187091  0.018434  1.086636   \n",
      "238  1.540910  0.509446  0.107334  ...  0.054736  0.055362  1.106575   \n",
      "243  1.722371  0.491278  0.092356  ...  0.103953  0.022563  0.755247   \n",
      "244  1.509921  0.965701  0.169045  ...  0.062934  0.049998  1.295947   \n",
      "245  1.364352  0.402151  0.102734  ...  0.066114  0.068032  1.089580   \n",
      "247  1.921449  0.503903  0.347050  ...  0.064734  0.011962  1.543737   \n",
      "249  1.612080  0.580269  0.073556  ...  0.054154  0.012473  1.110375   \n",
      "250  1.175884  0.460555  0.133870  ...  0.071979  0.074640  1.401435   \n",
      "251  0.626612  0.491829  0.066727  ...  0.059630  0.100358  1.992884   \n",
      "253  1.046283  0.344664  0.263102  ...  0.039862  0.000000  1.787707   \n",
      "255  1.351286  0.290644  0.291243  ...  0.024960  0.203422  1.585894   \n",
      "257  1.424101  0.389431  0.231206  ...  0.109228  0.237371  1.157966   \n",
      "259  0.688207  0.983205  0.082616  ...  0.029509  0.000000  2.335471   \n",
      "260  2.333328  0.396088  0.358947  ...  0.037968  0.309240  1.478309   \n",
      "261  0.400177  0.950645  0.167484  ...  0.037858  0.043329  2.216638   \n",
      "262  1.776613  0.617321  0.255815  ...  0.081674  0.000000  2.094285   \n",
      "263  0.839196  0.829542  0.134914  ...  0.034061  0.000000  2.388044   \n",
      "264  0.742169  1.057181  0.094176  ...  0.028272  0.000000  2.152071   \n",
      "266  1.790584  0.422939  0.119389  ...  0.089940  0.152792  1.218017   \n",
      "267  0.971563  0.205006  0.075575  ...  0.135554  0.224099  1.350498   \n",
      "268  1.063120  0.528915  0.136683  ...  0.024585  0.293851  1.767306   \n",
      "269  0.841885  0.615589  0.110709  ...  0.144203  0.070341  0.996750   \n",
      "270  1.866839  0.204724  0.261435  ...  0.019166  0.113689  1.534997   \n",
      "271  0.957526  0.590531  0.081902  ...  0.033770  0.024475  1.418425   \n",
      "281  2.480742  0.779922  0.485772  ...  0.086912  0.003670  1.567627   \n",
      "\n",
      "         2042      2043      2044      2045      2046      2047  label  \n",
      "2    0.416545  0.167183  0.079498  0.201032  0.974229  0.551655      0  \n",
      "12   0.346790  0.183561  0.118613  0.135509  0.736781  0.511532      0  \n",
      "22   0.808862  0.131035  0.117914  0.217650  0.737335  0.926838      0  \n",
      "25   0.992580  0.164288  0.137705  0.206687  0.638409  0.914038      0  \n",
      "48   0.682983  0.201357  0.058856  0.280312  0.776000  0.989758      0  \n",
      "74   0.736583  0.223118  0.015967  0.359678  0.789938  1.008450      0  \n",
      "75   0.715953  0.208401  0.083757  0.183648  0.731138  1.187703      0  \n",
      "85   0.742716  0.228559  0.077616  0.259635  0.765166  1.144554      0  \n",
      "102  0.743762  0.215843  0.072873  0.209154  0.724681  0.870680      0  \n",
      "106  0.630376  0.221892  0.035074  0.272606  0.894473  1.077865      0  \n",
      "130  0.912646  0.167052  0.161226  0.319273  0.542155  0.842571      0  \n",
      "138  0.797933  0.202445  0.058713  0.191381  0.565844  0.933795      0  \n",
      "145  0.774397  0.202801  0.174496  0.241500  0.792922  1.070261      0  \n",
      "150  0.889985  0.212812  0.045201  0.258058  0.667327  0.943764      0  \n",
      "174  0.662375  0.200676  0.125708  0.241459  0.828893  0.676831      0  \n",
      "181  0.904679  0.186330  0.100102  0.180639  0.736041  0.923635      0  \n",
      "190  0.937312  0.204058  0.053787  0.259670  0.703208  0.752196      0  \n",
      "209  0.352351  0.142521  0.137192  0.262437  0.666259  0.319803      1  \n",
      "210  0.137099  0.057090  0.077535  0.150690  0.921264  0.433182      1  \n",
      "213  0.384896  0.078656  0.081697  0.216090  0.850402  0.279928      1  \n",
      "214  0.616703  0.145985  0.160469  0.240406  0.868228  0.524331      1  \n",
      "215  0.386891  0.204617  0.238894  0.114696  0.619751  0.781018      1  \n",
      "216  0.416309  0.040646  0.124984  0.115057  0.882333  0.454049      1  \n",
      "218  0.587763  0.107611  0.139749  0.160496  0.887858  0.219843      1  \n",
      "219  0.535982  0.037952  0.204218  0.188316  0.737090  0.443145      1  \n",
      "220  0.149484  0.075640  0.172012  0.186486  0.519078  0.307328      1  \n",
      "221  0.237416  0.171242  0.230759  0.136544  0.877873  0.344919      1  \n",
      "222  0.408842  0.043710  0.059271  0.298724  0.478578  0.444622      1  \n",
      "223  0.391098  0.057361  0.162599  0.031447  1.217536  0.375514      1  \n",
      "224  0.241937  0.108652  0.271207  0.171421  1.017556  0.346123      1  \n",
      "226  0.386262  0.175017  0.155291  0.297609  0.624413  0.950418      1  \n",
      "227  0.412475  0.109990  0.193026  0.152518  0.657129  0.473241      1  \n",
      "228  0.397273  0.117697  0.096260  0.118650  0.837686  0.587704      1  \n",
      "235  0.328264  0.140275  0.109719  0.111616  1.002940  0.344186      1  \n",
      "237  0.171677  0.172755  0.038828  0.139887  0.675493  0.240656      1  \n",
      "238  0.491702  0.165634  0.081019  0.159987  0.818916  0.582376      1  \n",
      "243  0.374448  0.095514  0.099452  0.184220  0.782170  0.565623      1  \n",
      "244  0.257060  0.141652  0.116515  0.135933  1.078341  0.487973      1  \n",
      "245  0.165258  0.154244  0.123358  0.148631  0.810382  0.306669      1  \n",
      "247  0.498409  0.254291  0.026790  0.198089  0.691949  0.873415      1  \n",
      "249  0.192543  0.116083  0.061221  0.096828  1.225917  0.450372      1  \n",
      "250  0.444559  0.108227  0.205264  0.058651  1.030439  0.547721      1  \n",
      "251  0.521204  0.100497  0.125704  0.265987  1.346517  0.519698      1  \n",
      "253  0.628076  0.075639  0.001916  0.233872  1.080262  1.114756      1  \n",
      "255  0.771955  0.110749  0.002366  0.600132  0.958139  0.671934      1  \n",
      "257  1.176963  0.058140  0.041223  0.921218  1.227301  0.257243      1  \n",
      "259  0.241051  0.125044  0.019633  0.138048  1.358484  1.010652      1  \n",
      "260  0.672412  0.154150  0.000000  0.471614  0.661613  0.628898      1  \n",
      "261  0.499308  0.077015  0.007182  0.227484  1.306836  1.053514      1  \n",
      "262  0.855685  0.124365  0.060272  0.587612  1.321070  0.356565      1  \n",
      "263  0.571412  0.093766  0.007996  0.110367  1.149292  0.605126      1  \n",
      "264  0.172386  0.133546  0.045878  0.109677  1.190827  0.835022      1  \n",
      "266  0.880673  0.117115  0.075863  0.267975  0.585705  0.690117      1  \n",
      "267  0.724553  0.021765  0.179106  0.166975  0.579740  0.692277      1  \n",
      "268  0.587345  0.023709  0.000000  0.181079  1.217952  0.712232      1  \n",
      "269  0.408631  0.069517  0.044293  0.111228  0.447498  0.860770      1  \n",
      "270  0.635159  0.083481  0.002786  0.421201  0.612583  0.919466      1  \n",
      "271  0.845222  0.032476  0.036243  0.463798  1.200271  0.839567      1  \n",
      "281  0.537099  0.230956  0.051180  0.232040  0.816560  1.003793      0  \n",
      "\n",
      "[59 rows x 2049 columns]\n",
      "Accuracy: 0.863013698630137\n",
      "F1 Score: 0.6721311475409836\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "# ==========================\n",
    "# Cargar los Embeddings\n",
    "# ==========================\n",
    "file_path = \"embeddings.csv\"  # Cambia con la ruta correcta\n",
    "\n",
    "\n",
    "print(\"Anomaly Detector\")\n",
    "anomalies = AnomalyDetector(file_path,0.2)\n",
    "\n",
    "print(anomalies)\n",
    "\n",
    "\n",
    "true_labels = df[\"label\"]\n",
    "predicted_labels=np.where(df.index.isin(anomalies.index), 1, 0)\n",
    "acc= accuracy_score(true_labels, predicted_labels)\n",
    "f1 = f1_score(true_labels, predicted_labels)\n",
    "print(\"Accuracy:\", acc)\n",
    "print(\"F1 Score:\", f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "7d19e662",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anomaly Detector\n",
      "             0         1          2          3          4          5  \\\n",
      "1    85.229996  4.675968 -53.141420  -9.637234 -214.40220 -18.426817   \n",
      "4    87.173060  6.110612 -55.606724  -5.331498 -215.95230 -18.256690   \n",
      "9    89.009200  6.396141 -53.122093  -3.047558 -215.05301 -20.361510   \n",
      "12   87.688190  5.572481 -48.674942  -3.559689 -213.26302 -22.216146   \n",
      "21   86.384250  4.861780 -50.735940  -6.241511 -210.22803 -20.669264   \n",
      "..         ...       ...        ...        ...        ...        ...   \n",
      "273  87.821340  4.975814 -48.848260  -3.769339 -209.41348 -22.609660   \n",
      "276  82.375370  3.913394 -49.141052  -9.592222 -212.40822 -19.732508   \n",
      "280  90.488710  7.060682 -51.876213   0.334909 -212.11804 -21.653784   \n",
      "282  87.273094  4.883232 -44.166435   0.810245 -201.20331 -25.145105   \n",
      "287  79.988800  2.955720 -48.465008 -12.517033 -212.16797 -19.065527   \n",
      "\n",
      "             6          7          8          9  ...         55         56  \\\n",
      "1    -9.321927 -60.085340  88.949210 -164.92238  ... -28.953080  84.478950   \n",
      "4    -9.162456 -61.853355  93.752940 -156.88486  ... -30.378138  83.284515   \n",
      "9   -10.743657 -61.915290  95.234740 -155.52968  ... -30.925585  83.051110   \n",
      "12  -13.756534 -62.481540  94.979680 -155.64178  ... -34.466377  81.733400   \n",
      "21  -10.064561 -59.623010  89.689156 -161.12831  ... -26.282187  84.644530   \n",
      "..         ...        ...        ...        ...  ...        ...        ...   \n",
      "273 -11.402684 -60.357850  91.544060 -159.34499  ... -26.645855  84.670166   \n",
      "276 -13.028310 -61.968190  90.157240 -160.39777  ... -35.711660  81.200874   \n",
      "280 -10.735070 -61.167713  95.975990 -151.21925  ... -29.672987  82.051636   \n",
      "282 -13.074054 -59.701122  91.505516 -150.83281  ... -26.634184  81.679756   \n",
      "287 -13.332780 -61.968170  88.031654 -163.42476  ... -36.965412  80.996480   \n",
      "\n",
      "            57         58         59         60          61         62  \\\n",
      "1   -18.184780 -81.960220 -62.125360  51.790607 -108.141430 -44.113520   \n",
      "4   -14.335884 -84.606964 -60.562954  57.265804 -104.469860 -54.968810   \n",
      "9   -11.595136 -82.699165 -58.773415  59.418278 -103.868650 -55.336468   \n",
      "12   -7.119973 -82.174540 -55.095900  60.692036 -100.820984 -56.644340   \n",
      "21  -17.745441 -78.181790 -60.881866  53.387547 -108.494760 -42.659360   \n",
      "..         ...        ...        ...        ...         ...        ...   \n",
      "273 -15.596196 -76.725200 -59.742450  55.790596 -108.405860 -43.913550   \n",
      "276  -9.932976 -84.222520 -56.059746  55.539753 -100.746900 -52.944390   \n",
      "280 -10.359128 -80.064210 -57.322754  60.892820 -102.944214 -55.397700   \n",
      "282 -11.435102 -71.926630 -55.579840  58.044360 -104.507220 -44.962517   \n",
      "287 -10.602426 -85.012720 -56.062065  53.388683 -100.766910 -50.989540   \n",
      "\n",
      "            63  label  \n",
      "1   -195.51599      0  \n",
      "4   -196.94055      0  \n",
      "9   -196.42894      0  \n",
      "12  -191.63312      0  \n",
      "21  -194.91678      0  \n",
      "..         ...    ...  \n",
      "273 -194.84555      0  \n",
      "276 -187.63728      0  \n",
      "280 -195.63757      0  \n",
      "282 -188.10464      0  \n",
      "287 -185.45657      0  \n",
      "\n",
      "[87 rows x 65 columns]\n",
      "Accuracy: 0.7328767123287672\n",
      "F1 Score: 0.48\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "# ==========================\n",
    "# Cargar los Embeddings\n",
    "# ==========================\n",
    "\n",
    "df = pd.DataFrame(embeddings)\n",
    "df['label'] = labels  # última columna = etiqueta\n",
    "\n",
    "df.to_csv(\"tus_embeddings.csv\", index=False)\n",
    "\n",
    "file_path = \"tus_embeddings.csv\"  # Cambia con la ruta correcta\n",
    "\n",
    "\n",
    "print(\"Anomaly Detector\")\n",
    "anomalies = AnomalyDetector(file_path,0.05)\n",
    "\n",
    "print(anomalies)\n",
    "\n",
    "\n",
    "true_labels = df[\"label\"]\n",
    "predicted_labels=np.where(df.index.isin(anomalies.index), 1, 0)\n",
    "acc= accuracy_score(true_labels, predicted_labels)\n",
    "f1 = f1_score(true_labels, predicted_labels)\n",
    "print(\"Accuracy:\", acc)\n",
    "print(\"F1 Score:\", f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbd15573",
   "metadata": {},
   "source": [
    "METODO ANTONIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "e430d13d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "class GDAOneClassTorch:\n",
    "    def fit(self, X):\n",
    "        \"\"\"\n",
    "        Ajusta el modelo GDA para una sola clase usando PyTorch.\n",
    "        :param X: Tensor de forma (n_samples, n_features)\n",
    "        \"\"\"\n",
    "        self.mu = X.mean(dim=0)\n",
    "        self.centered = X - self.mu\n",
    "        self.sigma = torch.matmul(self.centered.T, self.centered) / X.shape[0]     #calcula la matriz de covarianzas\n",
    "\n",
    "        # Regularización para evitar matriz singular\n",
    "        epsilon = 1e-5\n",
    "        self.sigma += epsilon * torch.eye(self.sigma.shape[0])\n",
    "        self.inv_sigma = torch.inverse(self.sigma)\n",
    "        self.det_sigma = torch.det(self.sigma)\n",
    "\n",
    "    def score(self, X):\n",
    "        centered = X - self.mu\n",
    "        tmp = torch.matmul(centered, self.inv_sigma)\n",
    "        quad_form = (tmp * centered).sum(dim=1)\n",
    "        return -0.5 * quad_form  # Cuanto más positivo, más anómalo\n",
    "\n",
    "    def predict(self, X, threshold):\n",
    "        scores = self.score(X)\n",
    "        return (scores < threshold).int()  # umbral ajustado según el score, no la densidad\n",
    "\n",
    "\n",
    "    def print_parameters(self):\n",
    "        \"\"\"\n",
    "        Imprime el vector de medias y la matriz de covarianza.\n",
    "        \"\"\"\n",
    "        print(\"Vector de medias (mu):\")\n",
    "        print(self.mu)\n",
    "        print(\"\\nMatriz de covarianza (sigma):\")\n",
    "        print(self.sigma)\n",
    "\n",
    "    def print_score(self, X):\n",
    "      \"\"\"\n",
    "      Imprime y retorna la densidad de cada punto en X.\n",
    "      :param X: Tensor (n_samples, n_features)\n",
    "      :return: Diccionario {índice: densidad}\n",
    "      \"\"\"\n",
    "      probs = self.score(X)\n",
    "      scores = dict()\n",
    "\n",
    "      for i, p in enumerate(probs):\n",
    "          valor = p.item()\n",
    "          print(f\"Densidad del punto {i}: {valor:.6f}\")\n",
    "          scores[i] = valor\n",
    "\n",
    "      return scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "0ba42394",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([292])\n",
      "Ejemplo 0: Predicción = 0, Etiqueta real = 0\n",
      "Ejemplo 1: Predicción = 0, Etiqueta real = 0\n",
      "Ejemplo 2: Predicción = 0, Etiqueta real = 0\n",
      "Ejemplo 3: Predicción = 0, Etiqueta real = 0\n",
      "Ejemplo 4: Predicción = 0, Etiqueta real = 0\n",
      "Ejemplo 5: Predicción = 0, Etiqueta real = 0\n",
      "Ejemplo 6: Predicción = 0, Etiqueta real = 0\n",
      "Ejemplo 7: Predicción = 0, Etiqueta real = 0\n",
      "Ejemplo 8: Predicción = 0, Etiqueta real = 0\n",
      "Ejemplo 9: Predicción = 0, Etiqueta real = 0\n",
      "Ejemplo 10: Predicción = 0, Etiqueta real = 0\n",
      "Ejemplo 11: Predicción = 0, Etiqueta real = 0\n",
      "Ejemplo 12: Predicción = 0, Etiqueta real = 0\n",
      "Ejemplo 13: Predicción = 0, Etiqueta real = 0\n",
      "Ejemplo 14: Predicción = 0, Etiqueta real = 0\n",
      "Ejemplo 15: Predicción = 0, Etiqueta real = 0\n",
      "Ejemplo 16: Predicción = 0, Etiqueta real = 0\n",
      "Ejemplo 17: Predicción = 0, Etiqueta real = 0\n",
      "Ejemplo 18: Predicción = 0, Etiqueta real = 0\n",
      "Ejemplo 19: Predicción = 0, Etiqueta real = 0\n",
      "Ejemplo 20: Predicción = 0, Etiqueta real = 0\n",
      "Ejemplo 21: Predicción = 0, Etiqueta real = 0\n",
      "Ejemplo 22: Predicción = 0, Etiqueta real = 0\n",
      "Ejemplo 23: Predicción = 0, Etiqueta real = 0\n",
      "Ejemplo 24: Predicción = 0, Etiqueta real = 0\n",
      "Ejemplo 25: Predicción = 0, Etiqueta real = 0\n",
      "Ejemplo 26: Predicción = 0, Etiqueta real = 0\n",
      "Ejemplo 27: Predicción = 0, Etiqueta real = 0\n",
      "Ejemplo 28: Predicción = 0, Etiqueta real = 0\n",
      "Ejemplo 29: Predicción = 0, Etiqueta real = 0\n",
      "Ejemplo 30: Predicción = 0, Etiqueta real = 0\n",
      "Ejemplo 31: Predicción = 0, Etiqueta real = 0\n",
      "Ejemplo 32: Predicción = 0, Etiqueta real = 0\n",
      "Ejemplo 33: Predicción = 0, Etiqueta real = 0\n",
      "Ejemplo 34: Predicción = 0, Etiqueta real = 0\n",
      "Ejemplo 35: Predicción = 0, Etiqueta real = 0\n",
      "Ejemplo 36: Predicción = 0, Etiqueta real = 0\n",
      "Ejemplo 37: Predicción = 0, Etiqueta real = 0\n",
      "Ejemplo 38: Predicción = 0, Etiqueta real = 0\n",
      "Ejemplo 39: Predicción = 0, Etiqueta real = 0\n",
      "Ejemplo 40: Predicción = 0, Etiqueta real = 0\n",
      "Ejemplo 41: Predicción = 0, Etiqueta real = 0\n",
      "Ejemplo 42: Predicción = 0, Etiqueta real = 0\n",
      "Ejemplo 43: Predicción = 0, Etiqueta real = 0\n",
      "Ejemplo 44: Predicción = 0, Etiqueta real = 0\n",
      "Ejemplo 45: Predicción = 0, Etiqueta real = 0\n",
      "Ejemplo 46: Predicción = 0, Etiqueta real = 0\n",
      "Ejemplo 47: Predicción = 0, Etiqueta real = 0\n",
      "Ejemplo 48: Predicción = 0, Etiqueta real = 0\n",
      "Ejemplo 49: Predicción = 0, Etiqueta real = 0\n",
      "Ejemplo 50: Predicción = 0, Etiqueta real = 0\n",
      "Ejemplo 51: Predicción = 0, Etiqueta real = 0\n",
      "Ejemplo 52: Predicción = 0, Etiqueta real = 0\n",
      "Ejemplo 53: Predicción = 0, Etiqueta real = 0\n",
      "Ejemplo 54: Predicción = 0, Etiqueta real = 0\n",
      "Ejemplo 55: Predicción = 0, Etiqueta real = 0\n",
      "Ejemplo 56: Predicción = 0, Etiqueta real = 0\n",
      "Ejemplo 57: Predicción = 0, Etiqueta real = 0\n",
      "Ejemplo 58: Predicción = 0, Etiqueta real = 0\n",
      "Ejemplo 59: Predicción = 0, Etiqueta real = 0\n",
      "Ejemplo 60: Predicción = 0, Etiqueta real = 0\n",
      "Ejemplo 61: Predicción = 0, Etiqueta real = 0\n",
      "Ejemplo 62: Predicción = 0, Etiqueta real = 0\n",
      "Ejemplo 63: Predicción = 0, Etiqueta real = 0\n",
      "Ejemplo 64: Predicción = 0, Etiqueta real = 0\n",
      "Ejemplo 65: Predicción = 0, Etiqueta real = 0\n",
      "Ejemplo 66: Predicción = 0, Etiqueta real = 0\n",
      "Ejemplo 67: Predicción = 0, Etiqueta real = 0\n",
      "Ejemplo 68: Predicción = 0, Etiqueta real = 0\n",
      "Ejemplo 69: Predicción = 0, Etiqueta real = 0\n",
      "Ejemplo 70: Predicción = 0, Etiqueta real = 0\n",
      "Ejemplo 71: Predicción = 0, Etiqueta real = 0\n",
      "Ejemplo 72: Predicción = 0, Etiqueta real = 0\n",
      "Ejemplo 73: Predicción = 0, Etiqueta real = 0\n",
      "Ejemplo 74: Predicción = 0, Etiqueta real = 0\n",
      "Ejemplo 75: Predicción = 0, Etiqueta real = 0\n",
      "Ejemplo 76: Predicción = 0, Etiqueta real = 0\n",
      "Ejemplo 77: Predicción = 0, Etiqueta real = 0\n",
      "Ejemplo 78: Predicción = 0, Etiqueta real = 0\n",
      "Ejemplo 79: Predicción = 0, Etiqueta real = 0\n",
      "Ejemplo 80: Predicción = 0, Etiqueta real = 0\n",
      "Ejemplo 81: Predicción = 0, Etiqueta real = 0\n",
      "Ejemplo 82: Predicción = 0, Etiqueta real = 0\n",
      "Ejemplo 83: Predicción = 0, Etiqueta real = 0\n",
      "Ejemplo 84: Predicción = 0, Etiqueta real = 0\n",
      "Ejemplo 85: Predicción = 0, Etiqueta real = 0\n",
      "Ejemplo 86: Predicción = 0, Etiqueta real = 0\n",
      "Ejemplo 87: Predicción = 0, Etiqueta real = 0\n",
      "Ejemplo 88: Predicción = 0, Etiqueta real = 0\n",
      "Ejemplo 89: Predicción = 0, Etiqueta real = 0\n",
      "Ejemplo 90: Predicción = 0, Etiqueta real = 0\n",
      "Ejemplo 91: Predicción = 0, Etiqueta real = 0\n",
      "Ejemplo 92: Predicción = 0, Etiqueta real = 0\n",
      "Ejemplo 93: Predicción = 0, Etiqueta real = 0\n",
      "Ejemplo 94: Predicción = 0, Etiqueta real = 0\n",
      "Ejemplo 95: Predicción = 0, Etiqueta real = 0\n",
      "Ejemplo 96: Predicción = 0, Etiqueta real = 0\n",
      "Ejemplo 97: Predicción = 0, Etiqueta real = 0\n",
      "Ejemplo 98: Predicción = 0, Etiqueta real = 0\n",
      "Ejemplo 99: Predicción = 0, Etiqueta real = 0\n",
      "Ejemplo 100: Predicción = 0, Etiqueta real = 0\n",
      "Ejemplo 101: Predicción = 0, Etiqueta real = 0\n",
      "Ejemplo 102: Predicción = 0, Etiqueta real = 0\n",
      "Ejemplo 103: Predicción = 0, Etiqueta real = 0\n",
      "Ejemplo 104: Predicción = 0, Etiqueta real = 0\n",
      "Ejemplo 105: Predicción = 0, Etiqueta real = 0\n",
      "Ejemplo 106: Predicción = 0, Etiqueta real = 0\n",
      "Ejemplo 107: Predicción = 0, Etiqueta real = 0\n",
      "Ejemplo 108: Predicción = 0, Etiqueta real = 0\n",
      "Ejemplo 109: Predicción = 0, Etiqueta real = 0\n",
      "Ejemplo 110: Predicción = 0, Etiqueta real = 0\n",
      "Ejemplo 111: Predicción = 0, Etiqueta real = 0\n",
      "Ejemplo 112: Predicción = 0, Etiqueta real = 0\n",
      "Ejemplo 113: Predicción = 0, Etiqueta real = 0\n",
      "Ejemplo 114: Predicción = 0, Etiqueta real = 0\n",
      "Ejemplo 115: Predicción = 0, Etiqueta real = 0\n",
      "Ejemplo 116: Predicción = 0, Etiqueta real = 0\n",
      "Ejemplo 117: Predicción = 0, Etiqueta real = 0\n",
      "Ejemplo 118: Predicción = 0, Etiqueta real = 0\n",
      "Ejemplo 119: Predicción = 0, Etiqueta real = 0\n",
      "Ejemplo 120: Predicción = 0, Etiqueta real = 0\n",
      "Ejemplo 121: Predicción = 0, Etiqueta real = 0\n",
      "Ejemplo 122: Predicción = 0, Etiqueta real = 0\n",
      "Ejemplo 123: Predicción = 0, Etiqueta real = 0\n",
      "Ejemplo 124: Predicción = 0, Etiqueta real = 0\n",
      "Ejemplo 125: Predicción = 0, Etiqueta real = 0\n",
      "Ejemplo 126: Predicción = 0, Etiqueta real = 0\n",
      "Ejemplo 127: Predicción = 0, Etiqueta real = 0\n",
      "Ejemplo 128: Predicción = 0, Etiqueta real = 0\n",
      "Ejemplo 129: Predicción = 0, Etiqueta real = 0\n",
      "Ejemplo 130: Predicción = 0, Etiqueta real = 0\n",
      "Ejemplo 131: Predicción = 0, Etiqueta real = 0\n",
      "Ejemplo 132: Predicción = 0, Etiqueta real = 0\n",
      "Ejemplo 133: Predicción = 0, Etiqueta real = 0\n",
      "Ejemplo 134: Predicción = 0, Etiqueta real = 0\n",
      "Ejemplo 135: Predicción = 0, Etiqueta real = 0\n",
      "Ejemplo 136: Predicción = 0, Etiqueta real = 0\n",
      "Ejemplo 137: Predicción = 0, Etiqueta real = 0\n",
      "Ejemplo 138: Predicción = 0, Etiqueta real = 0\n",
      "Ejemplo 139: Predicción = 0, Etiqueta real = 0\n",
      "Ejemplo 140: Predicción = 0, Etiqueta real = 0\n",
      "Ejemplo 141: Predicción = 0, Etiqueta real = 0\n",
      "Ejemplo 142: Predicción = 0, Etiqueta real = 0\n",
      "Ejemplo 143: Predicción = 0, Etiqueta real = 0\n",
      "Ejemplo 144: Predicción = 0, Etiqueta real = 0\n",
      "Ejemplo 145: Predicción = 0, Etiqueta real = 0\n",
      "Ejemplo 146: Predicción = 0, Etiqueta real = 0\n",
      "Ejemplo 147: Predicción = 0, Etiqueta real = 0\n",
      "Ejemplo 148: Predicción = 0, Etiqueta real = 0\n",
      "Ejemplo 149: Predicción = 0, Etiqueta real = 0\n",
      "Ejemplo 150: Predicción = 0, Etiqueta real = 0\n",
      "Ejemplo 151: Predicción = 0, Etiqueta real = 0\n",
      "Ejemplo 152: Predicción = 0, Etiqueta real = 0\n",
      "Ejemplo 153: Predicción = 0, Etiqueta real = 0\n",
      "Ejemplo 154: Predicción = 0, Etiqueta real = 0\n",
      "Ejemplo 155: Predicción = 0, Etiqueta real = 0\n",
      "Ejemplo 156: Predicción = 0, Etiqueta real = 0\n",
      "Ejemplo 157: Predicción = 0, Etiqueta real = 0\n",
      "Ejemplo 158: Predicción = 0, Etiqueta real = 0\n",
      "Ejemplo 159: Predicción = 0, Etiqueta real = 0\n",
      "Ejemplo 160: Predicción = 0, Etiqueta real = 0\n",
      "Ejemplo 161: Predicción = 0, Etiqueta real = 0\n",
      "Ejemplo 162: Predicción = 0, Etiqueta real = 0\n",
      "Ejemplo 163: Predicción = 0, Etiqueta real = 0\n",
      "Ejemplo 164: Predicción = 0, Etiqueta real = 0\n",
      "Ejemplo 165: Predicción = 0, Etiqueta real = 0\n",
      "Ejemplo 166: Predicción = 0, Etiqueta real = 0\n",
      "Ejemplo 167: Predicción = 0, Etiqueta real = 0\n",
      "Ejemplo 168: Predicción = 0, Etiqueta real = 0\n",
      "Ejemplo 169: Predicción = 0, Etiqueta real = 0\n",
      "Ejemplo 170: Predicción = 0, Etiqueta real = 0\n",
      "Ejemplo 171: Predicción = 0, Etiqueta real = 0\n",
      "Ejemplo 172: Predicción = 0, Etiqueta real = 0\n",
      "Ejemplo 173: Predicción = 0, Etiqueta real = 0\n",
      "Ejemplo 174: Predicción = 0, Etiqueta real = 0\n",
      "Ejemplo 175: Predicción = 0, Etiqueta real = 0\n",
      "Ejemplo 176: Predicción = 0, Etiqueta real = 0\n",
      "Ejemplo 177: Predicción = 0, Etiqueta real = 0\n",
      "Ejemplo 178: Predicción = 0, Etiqueta real = 0\n",
      "Ejemplo 179: Predicción = 0, Etiqueta real = 0\n",
      "Ejemplo 180: Predicción = 0, Etiqueta real = 0\n",
      "Ejemplo 181: Predicción = 0, Etiqueta real = 0\n",
      "Ejemplo 182: Predicción = 0, Etiqueta real = 0\n",
      "Ejemplo 183: Predicción = 0, Etiqueta real = 0\n",
      "Ejemplo 184: Predicción = 0, Etiqueta real = 0\n",
      "Ejemplo 185: Predicción = 0, Etiqueta real = 0\n",
      "Ejemplo 186: Predicción = 0, Etiqueta real = 0\n",
      "Ejemplo 187: Predicción = 0, Etiqueta real = 0\n",
      "Ejemplo 188: Predicción = 0, Etiqueta real = 0\n",
      "Ejemplo 189: Predicción = 0, Etiqueta real = 0\n",
      "Ejemplo 190: Predicción = 0, Etiqueta real = 0\n",
      "Ejemplo 191: Predicción = 0, Etiqueta real = 0\n",
      "Ejemplo 192: Predicción = 0, Etiqueta real = 0\n",
      "Ejemplo 193: Predicción = 0, Etiqueta real = 0\n",
      "Ejemplo 194: Predicción = 0, Etiqueta real = 0\n",
      "Ejemplo 195: Predicción = 0, Etiqueta real = 0\n",
      "Ejemplo 196: Predicción = 0, Etiqueta real = 0\n",
      "Ejemplo 197: Predicción = 0, Etiqueta real = 0\n",
      "Ejemplo 198: Predicción = 0, Etiqueta real = 0\n",
      "Ejemplo 199: Predicción = 0, Etiqueta real = 0\n",
      "Ejemplo 200: Predicción = 0, Etiqueta real = 0\n",
      "Ejemplo 201: Predicción = 0, Etiqueta real = 0\n",
      "Ejemplo 202: Predicción = 0, Etiqueta real = 0\n",
      "Ejemplo 203: Predicción = 0, Etiqueta real = 0\n",
      "Ejemplo 204: Predicción = 0, Etiqueta real = 0\n",
      "Ejemplo 205: Predicción = 0, Etiqueta real = 0\n",
      "Ejemplo 206: Predicción = 0, Etiqueta real = 0\n",
      "Ejemplo 207: Predicción = 0, Etiqueta real = 0\n",
      "Ejemplo 208: Predicción = 0, Etiqueta real = 0\n",
      "Ejemplo 209: Predicción = 1, Etiqueta real = 1\n",
      "Ejemplo 210: Predicción = 1, Etiqueta real = 1\n",
      "Ejemplo 211: Predicción = 1, Etiqueta real = 1\n",
      "Ejemplo 212: Predicción = 1, Etiqueta real = 1\n",
      "Ejemplo 213: Predicción = 1, Etiqueta real = 1\n",
      "Ejemplo 214: Predicción = 1, Etiqueta real = 1\n",
      "Ejemplo 215: Predicción = 1, Etiqueta real = 1\n",
      "Ejemplo 216: Predicción = 1, Etiqueta real = 1\n",
      "Ejemplo 217: Predicción = 1, Etiqueta real = 1\n",
      "Ejemplo 218: Predicción = 1, Etiqueta real = 1\n",
      "Ejemplo 219: Predicción = 1, Etiqueta real = 1\n",
      "Ejemplo 220: Predicción = 1, Etiqueta real = 1\n",
      "Ejemplo 221: Predicción = 1, Etiqueta real = 1\n",
      "Ejemplo 222: Predicción = 1, Etiqueta real = 1\n",
      "Ejemplo 223: Predicción = 1, Etiqueta real = 1\n",
      "Ejemplo 224: Predicción = 1, Etiqueta real = 1\n",
      "Ejemplo 225: Predicción = 1, Etiqueta real = 1\n",
      "Ejemplo 226: Predicción = 1, Etiqueta real = 1\n",
      "Ejemplo 227: Predicción = 1, Etiqueta real = 1\n",
      "Ejemplo 228: Predicción = 1, Etiqueta real = 1\n",
      "Ejemplo 229: Predicción = 1, Etiqueta real = 1\n",
      "Ejemplo 230: Predicción = 1, Etiqueta real = 1\n",
      "Ejemplo 231: Predicción = 1, Etiqueta real = 1\n",
      "Ejemplo 232: Predicción = 1, Etiqueta real = 1\n",
      "Ejemplo 233: Predicción = 1, Etiqueta real = 1\n",
      "Ejemplo 234: Predicción = 1, Etiqueta real = 1\n",
      "Ejemplo 235: Predicción = 1, Etiqueta real = 1\n",
      "Ejemplo 236: Predicción = 1, Etiqueta real = 1\n",
      "Ejemplo 237: Predicción = 1, Etiqueta real = 1\n",
      "Ejemplo 238: Predicción = 1, Etiqueta real = 1\n",
      "Ejemplo 239: Predicción = 1, Etiqueta real = 1\n",
      "Ejemplo 240: Predicción = 1, Etiqueta real = 1\n",
      "Ejemplo 241: Predicción = 1, Etiqueta real = 1\n",
      "Ejemplo 242: Predicción = 1, Etiqueta real = 1\n",
      "Ejemplo 243: Predicción = 1, Etiqueta real = 1\n",
      "Ejemplo 244: Predicción = 1, Etiqueta real = 1\n",
      "Ejemplo 245: Predicción = 1, Etiqueta real = 1\n",
      "Ejemplo 246: Predicción = 1, Etiqueta real = 1\n",
      "Ejemplo 247: Predicción = 1, Etiqueta real = 1\n",
      "Ejemplo 248: Predicción = 1, Etiqueta real = 1\n",
      "Ejemplo 249: Predicción = 1, Etiqueta real = 1\n",
      "Ejemplo 250: Predicción = 1, Etiqueta real = 1\n",
      "Ejemplo 251: Predicción = 1, Etiqueta real = 1\n",
      "Ejemplo 252: Predicción = 1, Etiqueta real = 1\n",
      "Ejemplo 253: Predicción = 1, Etiqueta real = 1\n",
      "Ejemplo 254: Predicción = 1, Etiqueta real = 1\n",
      "Ejemplo 255: Predicción = 1, Etiqueta real = 1\n",
      "Ejemplo 256: Predicción = 1, Etiqueta real = 1\n",
      "Ejemplo 257: Predicción = 1, Etiqueta real = 1\n",
      "Ejemplo 258: Predicción = 1, Etiqueta real = 1\n",
      "Ejemplo 259: Predicción = 1, Etiqueta real = 1\n",
      "Ejemplo 260: Predicción = 1, Etiqueta real = 1\n",
      "Ejemplo 261: Predicción = 1, Etiqueta real = 1\n",
      "Ejemplo 262: Predicción = 1, Etiqueta real = 1\n",
      "Ejemplo 263: Predicción = 1, Etiqueta real = 1\n",
      "Ejemplo 264: Predicción = 1, Etiqueta real = 1\n",
      "Ejemplo 265: Predicción = 1, Etiqueta real = 1\n",
      "Ejemplo 266: Predicción = 1, Etiqueta real = 1\n",
      "Ejemplo 267: Predicción = 1, Etiqueta real = 1\n",
      "Ejemplo 268: Predicción = 1, Etiqueta real = 1\n",
      "Ejemplo 269: Predicción = 1, Etiqueta real = 1\n",
      "Ejemplo 270: Predicción = 1, Etiqueta real = 1\n",
      "Ejemplo 271: Predicción = 1, Etiqueta real = 1\n",
      "Ejemplo 272: Predicción = 0, Etiqueta real = 0\n",
      "Ejemplo 273: Predicción = 0, Etiqueta real = 0\n",
      "Ejemplo 274: Predicción = 0, Etiqueta real = 0\n",
      "Ejemplo 275: Predicción = 0, Etiqueta real = 0\n",
      "Ejemplo 276: Predicción = 0, Etiqueta real = 0\n",
      "Ejemplo 277: Predicción = 0, Etiqueta real = 0\n",
      "Ejemplo 278: Predicción = 0, Etiqueta real = 0\n",
      "Ejemplo 279: Predicción = 0, Etiqueta real = 0\n",
      "Ejemplo 280: Predicción = 0, Etiqueta real = 0\n",
      "Ejemplo 281: Predicción = 0, Etiqueta real = 0\n",
      "Ejemplo 282: Predicción = 0, Etiqueta real = 0\n",
      "Ejemplo 283: Predicción = 0, Etiqueta real = 0\n",
      "Ejemplo 284: Predicción = 0, Etiqueta real = 0\n",
      "Ejemplo 285: Predicción = 0, Etiqueta real = 0\n",
      "Ejemplo 286: Predicción = 0, Etiqueta real = 0\n",
      "Ejemplo 287: Predicción = 0, Etiqueta real = 0\n",
      "Ejemplo 288: Predicción = 0, Etiqueta real = 0\n",
      "Ejemplo 289: Predicción = 0, Etiqueta real = 0\n",
      "Ejemplo 290: Predicción = 0, Etiqueta real = 0\n",
      "Ejemplo 291: Predicción = 0, Etiqueta real = 0\n",
      "Accuracy: 1.0\n",
      "F1 Score: 1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score,f1_score\n",
    "file_path = \"embeddings.csv\"\n",
    "\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "df_normal = df[df['label'] == 0]\n",
    "embedding_columns = df.columns[:-1]  # nombres de columnas excepto la última\n",
    "embeddings_train = df_normal[embedding_columns].values\n",
    "model = GDAOneClassTorch()\n",
    "X_train = torch.tensor(embeddings_train, dtype=torch.float32)\n",
    "\n",
    "model.fit(X_train)\n",
    "\n",
    "\n",
    "embeddings = df[embedding_columns].values\n",
    "X_test = torch.tensor(embeddings, dtype=torch.float32)\n",
    "\n",
    "\n",
    "preds = model.predict(X_test, threshold=-120)\n",
    "print(preds.shape)\n",
    "\n",
    "# Paso 3: imprimir por pantalla (predicción y etiqueta real)\n",
    "for i, (p, real) in enumerate(zip(preds, df[\"label\"])):\n",
    "    print(f\"Ejemplo {i}: Predicción = {p.item()}, Etiqueta real = {real}\")\n",
    "\n",
    "true_labels = df[\"label\"]\n",
    "acc= accuracy_score(true_labels, preds)\n",
    "f1 = f1_score(true_labels, preds)\n",
    "print(\"Accuracy:\", acc)\n",
    "print(\"F1 Score:\", f1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "08938cf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector de medias (mu):\n",
      "tensor([1.0490, 0.6470, 0.1405,  ..., 0.1763, 0.7875, 0.6380])\n",
      "\n",
      "Matriz de covarianza (sigma):\n",
      "tensor([[ 1.3818e-02, -1.8820e-03, -9.0921e-04,  ...,  4.7015e-04,\n",
      "          5.0818e-03, -1.3453e-03],\n",
      "        [-1.8820e-03,  8.7657e-03,  1.1247e-03,  ..., -1.1773e-04,\n",
      "         -5.1083e-03,  2.6859e-07],\n",
      "        [-9.0921e-04,  1.1247e-03,  4.4453e-03,  ...,  1.0937e-03,\n",
      "         -3.8740e-03,  3.6731e-03],\n",
      "        ...,\n",
      "        [ 4.7015e-04, -1.1773e-04,  1.0937e-03,  ...,  2.0578e-03,\n",
      "         -9.2642e-04,  2.5566e-03],\n",
      "        [ 5.0818e-03, -5.1083e-03, -3.8740e-03,  ..., -9.2642e-04,\n",
      "          1.8766e-02, -2.5094e-03],\n",
      "        [-1.3453e-03,  2.6859e-07,  3.6731e-03,  ...,  2.5566e-03,\n",
      "         -2.5094e-03,  1.8755e-02]])\n",
      "Densidad del punto 0: -113.495369\n",
      "Densidad del punto 1: -113.356911\n",
      "Densidad del punto 2: -113.547157\n",
      "Densidad del punto 3: -113.380867\n",
      "Densidad del punto 4: -113.599045\n",
      "Densidad del punto 5: -113.521675\n",
      "Densidad del punto 6: -113.325233\n",
      "Densidad del punto 7: -113.592140\n",
      "Densidad del punto 8: -113.362076\n",
      "Densidad del punto 9: -113.363579\n",
      "Densidad del punto 10: -113.331413\n",
      "Densidad del punto 11: -113.493599\n",
      "Densidad del punto 12: -113.485626\n",
      "Densidad del punto 13: -113.510925\n",
      "Densidad del punto 14: -113.599236\n",
      "Densidad del punto 15: -113.497498\n",
      "Densidad del punto 16: -113.261749\n",
      "Densidad del punto 17: -113.338081\n",
      "Densidad del punto 18: -113.138428\n",
      "Densidad del punto 19: -113.473549\n",
      "Densidad del punto 20: -113.285614\n",
      "Densidad del punto 21: -113.509644\n",
      "Densidad del punto 22: -113.845139\n",
      "Densidad del punto 23: -113.744492\n",
      "Densidad del punto 24: -113.563194\n",
      "Densidad del punto 25: -113.712585\n",
      "Densidad del punto 26: -113.488518\n",
      "Densidad del punto 27: -113.319618\n",
      "Densidad del punto 28: -113.447334\n",
      "Densidad del punto 29: -113.363930\n",
      "Densidad del punto 30: -113.459282\n",
      "Densidad del punto 31: -113.255592\n",
      "Densidad del punto 32: -113.498512\n",
      "Densidad del punto 33: -113.415375\n",
      "Densidad del punto 34: -113.565643\n",
      "Densidad del punto 35: -113.657242\n",
      "Densidad del punto 36: -113.311356\n",
      "Densidad del punto 37: -113.533279\n",
      "Densidad del punto 38: -113.486290\n",
      "Densidad del punto 39: -113.408745\n",
      "Densidad del punto 40: -113.565445\n",
      "Densidad del punto 41: -113.516205\n",
      "Densidad del punto 42: -113.296028\n",
      "Densidad del punto 43: -113.653000\n",
      "Densidad del punto 44: -113.371811\n",
      "Densidad del punto 45: -113.446098\n",
      "Densidad del punto 46: -113.461189\n",
      "Densidad del punto 47: -113.282478\n",
      "Densidad del punto 48: -113.635254\n",
      "Densidad del punto 49: -112.470230\n",
      "Densidad del punto 50: -113.156128\n",
      "Densidad del punto 51: -113.421371\n",
      "Densidad del punto 52: -113.428627\n",
      "Densidad del punto 53: -113.431442\n",
      "Densidad del punto 54: -113.310112\n",
      "Densidad del punto 55: -113.625229\n",
      "Densidad del punto 56: -113.440224\n",
      "Densidad del punto 57: -113.450775\n",
      "Densidad del punto 58: -113.158966\n",
      "Densidad del punto 59: -113.555115\n",
      "Densidad del punto 60: -113.616493\n",
      "Densidad del punto 61: -113.334587\n",
      "Densidad del punto 62: -113.527946\n",
      "Densidad del punto 63: -113.317879\n",
      "Densidad del punto 64: -113.484100\n",
      "Densidad del punto 65: -113.476746\n",
      "Densidad del punto 66: -113.486267\n",
      "Densidad del punto 67: -113.491608\n",
      "Densidad del punto 68: -113.455795\n",
      "Densidad del punto 69: -113.584328\n",
      "Densidad del punto 70: -113.720055\n",
      "Densidad del punto 71: -113.472015\n",
      "Densidad del punto 72: -113.340485\n",
      "Densidad del punto 73: -113.601006\n",
      "Densidad del punto 74: -113.894081\n",
      "Densidad del punto 75: -113.767624\n",
      "Densidad del punto 76: -113.325050\n",
      "Densidad del punto 77: -113.538910\n",
      "Densidad del punto 78: -113.500916\n",
      "Densidad del punto 79: -113.457703\n",
      "Densidad del punto 80: -113.198769\n",
      "Densidad del punto 81: -113.793915\n",
      "Densidad del punto 82: -113.518761\n",
      "Densidad del punto 83: -113.375580\n",
      "Densidad del punto 84: -113.612579\n",
      "Densidad del punto 85: -113.752815\n",
      "Densidad del punto 86: -113.440346\n",
      "Densidad del punto 87: -113.664680\n",
      "Densidad del punto 88: -113.495239\n",
      "Densidad del punto 89: -113.630539\n",
      "Densidad del punto 90: -113.304184\n",
      "Densidad del punto 91: -113.480774\n",
      "Densidad del punto 92: -113.625008\n",
      "Densidad del punto 93: -113.465324\n",
      "Densidad del punto 94: -113.536461\n",
      "Densidad del punto 95: -113.634605\n",
      "Densidad del punto 96: -113.534554\n",
      "Densidad del punto 97: -113.456512\n",
      "Densidad del punto 98: -113.522583\n",
      "Densidad del punto 99: -113.223518\n",
      "Densidad del punto 100: -113.328316\n",
      "Densidad del punto 101: -113.628387\n",
      "Densidad del punto 102: -113.768906\n",
      "Densidad del punto 103: -113.247261\n",
      "Densidad del punto 104: -113.463341\n",
      "Densidad del punto 105: -113.369415\n",
      "Densidad del punto 106: -113.809235\n",
      "Densidad del punto 107: -113.490143\n",
      "Densidad del punto 108: -113.528282\n",
      "Densidad del punto 109: -113.370934\n",
      "Densidad del punto 110: -113.451508\n",
      "Densidad del punto 111: -113.418533\n",
      "Densidad del punto 112: -113.573288\n",
      "Densidad del punto 113: -113.377930\n",
      "Densidad del punto 114: -113.329834\n",
      "Densidad del punto 115: -113.457512\n",
      "Densidad del punto 116: -113.595322\n",
      "Densidad del punto 117: -113.458344\n",
      "Densidad del punto 118: -113.597733\n",
      "Densidad del punto 119: -113.773613\n",
      "Densidad del punto 120: -113.463989\n",
      "Densidad del punto 121: -113.523514\n",
      "Densidad del punto 122: -113.432228\n",
      "Densidad del punto 123: -113.619614\n",
      "Densidad del punto 124: -113.468628\n",
      "Densidad del punto 125: -113.518745\n",
      "Densidad del punto 126: -113.549652\n",
      "Densidad del punto 127: -113.560852\n",
      "Densidad del punto 128: -113.654495\n",
      "Densidad del punto 129: -113.358322\n",
      "Densidad del punto 130: -113.843826\n",
      "Densidad del punto 131: -113.346886\n",
      "Densidad del punto 132: -113.338577\n",
      "Densidad del punto 133: -113.387192\n",
      "Densidad del punto 134: -113.553268\n",
      "Densidad del punto 135: -113.219917\n",
      "Densidad del punto 136: -113.304733\n",
      "Densidad del punto 137: -113.569794\n",
      "Densidad del punto 138: -113.921013\n",
      "Densidad del punto 139: -113.301712\n",
      "Densidad del punto 140: -113.754318\n",
      "Densidad del punto 141: -113.588005\n",
      "Densidad del punto 142: -113.363434\n",
      "Densidad del punto 143: -113.405243\n",
      "Densidad del punto 144: -112.541740\n",
      "Densidad del punto 145: -113.621574\n",
      "Densidad del punto 146: -113.344574\n",
      "Densidad del punto 147: -113.394714\n",
      "Densidad del punto 148: -113.300507\n",
      "Densidad del punto 149: -113.377419\n",
      "Densidad del punto 150: -113.825081\n",
      "Densidad del punto 151: -113.255615\n",
      "Densidad del punto 152: -113.451889\n",
      "Densidad del punto 153: -113.659073\n",
      "Densidad del punto 154: -113.612938\n",
      "Densidad del punto 155: -113.547997\n",
      "Densidad del punto 156: -113.462440\n",
      "Densidad del punto 157: -113.370438\n",
      "Densidad del punto 158: -113.551407\n",
      "Densidad del punto 159: -113.628799\n",
      "Densidad del punto 160: -113.546661\n",
      "Densidad del punto 161: -113.507721\n",
      "Densidad del punto 162: -113.546257\n",
      "Densidad del punto 163: -113.401978\n",
      "Densidad del punto 164: -113.543060\n",
      "Densidad del punto 165: -113.626816\n",
      "Densidad del punto 166: -113.635162\n",
      "Densidad del punto 167: -113.364937\n",
      "Densidad del punto 168: -113.403397\n",
      "Densidad del punto 169: -113.480560\n",
      "Densidad del punto 170: -113.427620\n",
      "Densidad del punto 171: -113.074455\n",
      "Densidad del punto 172: -113.569504\n",
      "Densidad del punto 173: -113.597549\n",
      "Densidad del punto 174: -113.846909\n",
      "Densidad del punto 175: -113.585968\n",
      "Densidad del punto 176: -113.406876\n",
      "Densidad del punto 177: -113.407036\n",
      "Densidad del punto 178: -113.398224\n",
      "Densidad del punto 179: -113.451836\n",
      "Densidad del punto 180: -113.540123\n",
      "Densidad del punto 181: -113.734077\n",
      "Densidad del punto 182: -113.631790\n",
      "Densidad del punto 183: -113.507561\n",
      "Densidad del punto 184: -113.695915\n",
      "Densidad del punto 185: -113.497726\n",
      "Densidad del punto 186: -113.418907\n",
      "Densidad del punto 187: -113.704163\n",
      "Densidad del punto 188: -113.405640\n",
      "Densidad del punto 189: -113.385086\n",
      "Densidad del punto 190: -113.649612\n",
      "Densidad del punto 191: -113.596161\n",
      "Densidad del punto 192: -113.582191\n",
      "Densidad del punto 193: -113.710144\n",
      "Densidad del punto 194: -113.468483\n",
      "Densidad del punto 195: -113.717987\n",
      "Densidad del punto 196: -113.499718\n",
      "Densidad del punto 197: -113.507538\n",
      "Densidad del punto 198: -113.435486\n",
      "Densidad del punto 199: -113.649506\n",
      "Densidad del punto 200: -113.513954\n",
      "Densidad del punto 201: -113.243530\n",
      "Densidad del punto 202: -113.671021\n",
      "Densidad del punto 203: -113.503296\n",
      "Densidad del punto 204: -113.394180\n",
      "Densidad del punto 205: -113.493690\n",
      "Densidad del punto 206: -113.687698\n",
      "Densidad del punto 207: -113.758148\n",
      "Densidad del punto 208: -113.606064\n",
      "Densidad del punto 209: -113.434540\n",
      "Densidad del punto 210: -113.681488\n",
      "Densidad del punto 211: -113.474800\n",
      "Densidad del punto 212: -113.427361\n",
      "Densidad del punto 213: -113.553459\n",
      "Densidad del punto 214: -113.574707\n",
      "Densidad del punto 215: -113.578056\n",
      "Densidad del punto 216: -113.477982\n",
      "Densidad del punto 217: -113.668350\n",
      "Densidad del punto 218: -113.867996\n",
      "Densidad del punto 219: -113.451233\n",
      "Densidad del punto 220: -113.495811\n",
      "Densidad del punto 221: -113.695358\n",
      "Densidad del punto 222: -113.605141\n",
      "Densidad del punto 223: -113.605209\n",
      "Densidad del punto 224: -113.599022\n",
      "Densidad del punto 225: -113.438591\n",
      "Densidad del punto 226: -113.525230\n",
      "Densidad del punto 227: -113.497131\n",
      "Densidad del punto 228: -113.665932\n",
      "Densidad del punto 0: -113.509018\n",
      "Densidad del punto 1: -113.358490\n",
      "Densidad del punto 2: -113.536865\n",
      "Densidad del punto 3: -113.386421\n",
      "Densidad del punto 4: -113.600441\n",
      "Densidad del punto 5: -113.508934\n",
      "Densidad del punto 6: -113.317787\n",
      "Densidad del punto 7: -113.592628\n",
      "Densidad del punto 8: -113.359711\n",
      "Densidad del punto 9: -113.359192\n",
      "Densidad del punto 10: -113.336922\n",
      "Densidad del punto 11: -113.503075\n",
      "Densidad del punto 12: -113.494034\n",
      "Densidad del punto 13: -113.506844\n",
      "Densidad del punto 14: -113.597122\n",
      "Densidad del punto 15: -113.496445\n",
      "Densidad del punto 16: -113.266655\n",
      "Densidad del punto 17: -113.346230\n",
      "Densidad del punto 18: -113.128181\n",
      "Densidad del punto 19: -113.485565\n",
      "Densidad del punto 20: -113.283447\n",
      "Densidad del punto 21: -113.516418\n",
      "Densidad del punto 22: -113.845139\n",
      "Densidad del punto 23: -113.737190\n",
      "Densidad del punto 24: -113.562775\n",
      "Densidad del punto 25: -113.690514\n",
      "Densidad del punto 26: -113.477966\n",
      "Densidad del punto 27: -113.320923\n",
      "Densidad del punto 28: -113.447937\n",
      "Densidad del punto 29: -113.360291\n",
      "Densidad del punto 30: -113.487175\n",
      "Densidad del punto 31: -113.234253\n",
      "Densidad del punto 32: -113.503593\n",
      "Densidad del punto 33: -113.413712\n",
      "Densidad del punto 34: -113.566711\n",
      "Densidad del punto 35: -113.663284\n",
      "Densidad del punto 36: -113.311020\n",
      "Densidad del punto 37: -113.534874\n",
      "Densidad del punto 38: -113.479874\n",
      "Densidad del punto 39: -113.404587\n",
      "Densidad del punto 40: -113.560066\n",
      "Densidad del punto 41: -113.506584\n",
      "Densidad del punto 42: -113.297195\n",
      "Densidad del punto 43: -113.658295\n",
      "Densidad del punto 44: -113.390533\n",
      "Densidad del punto 45: -113.463448\n",
      "Densidad del punto 46: -113.466217\n",
      "Densidad del punto 47: -113.279968\n",
      "Densidad del punto 48: -113.629593\n",
      "Densidad del punto 49: -112.465118\n",
      "Densidad del punto 50: -113.154129\n",
      "Densidad del punto 51: -113.417046\n",
      "Densidad del punto 52: -113.440689\n",
      "Densidad del punto 53: -113.417702\n",
      "Densidad del punto 54: -113.320450\n",
      "Densidad del punto 55: -113.629616\n",
      "Densidad del punto 56: -113.434402\n",
      "Densidad del punto 57: -113.465942\n",
      "Densidad del punto 58: -113.160255\n",
      "Densidad del punto 59: -113.555237\n",
      "Densidad del punto 60: -113.619247\n",
      "Densidad del punto 61: -113.343704\n",
      "Densidad del punto 62: -113.529121\n",
      "Densidad del punto 63: -113.320328\n",
      "Densidad del punto 64: -113.520729\n",
      "Densidad del punto 65: -113.494492\n",
      "Densidad del punto 66: -113.486023\n",
      "Densidad del punto 67: -113.484566\n",
      "Densidad del punto 68: -113.448555\n",
      "Densidad del punto 69: -113.573074\n",
      "Densidad del punto 70: -113.713699\n",
      "Densidad del punto 71: -113.480782\n",
      "Densidad del punto 72: -113.340370\n",
      "Densidad del punto 73: -113.603424\n",
      "Densidad del punto 74: -113.817650\n",
      "Densidad del punto 75: -113.768135\n",
      "Densidad del punto 76: -113.326157\n",
      "Densidad del punto 77: -113.531792\n",
      "Densidad del punto 78: -113.501480\n",
      "Densidad del punto 79: -113.453941\n",
      "Densidad del punto 80: -113.195518\n",
      "Densidad del punto 81: -113.797745\n",
      "Densidad del punto 82: -113.519753\n",
      "Densidad del punto 83: -113.369751\n",
      "Densidad del punto 84: -113.597443\n",
      "Densidad del punto 85: -113.738625\n",
      "Densidad del punto 86: -113.438156\n",
      "Densidad del punto 87: -113.689468\n",
      "Densidad del punto 88: -113.482857\n",
      "Densidad del punto 89: -113.629845\n",
      "Densidad del punto 90: -113.304314\n",
      "Densidad del punto 91: -113.473244\n",
      "Densidad del punto 92: -113.615837\n",
      "Densidad del punto 93: -113.458809\n",
      "Densidad del punto 94: -113.529800\n",
      "Densidad del punto 95: -113.633293\n",
      "Densidad del punto 96: -113.530418\n",
      "Densidad del punto 97: -113.464737\n",
      "Densidad del punto 98: -113.522697\n",
      "Densidad del punto 99: -113.225403\n",
      "Densidad del punto 100: -113.338570\n",
      "Densidad del punto 101: -113.640999\n",
      "Densidad del punto 102: -113.755646\n",
      "Densidad del punto 103: -113.255814\n",
      "Densidad del punto 104: -113.457230\n",
      "Densidad del punto 105: -113.364136\n",
      "Densidad del punto 106: -113.913818\n",
      "Densidad del punto 107: -113.490105\n",
      "Densidad del punto 108: -113.528221\n",
      "Densidad del punto 109: -113.376892\n",
      "Densidad del punto 110: -113.460014\n",
      "Densidad del punto 111: -113.423523\n",
      "Densidad del punto 112: -113.567764\n",
      "Densidad del punto 113: -113.380974\n",
      "Densidad del punto 114: -113.328583\n",
      "Densidad del punto 115: -113.454010\n",
      "Densidad del punto 116: -113.590096\n",
      "Densidad del punto 117: -113.457367\n",
      "Densidad del punto 118: -113.610458\n",
      "Densidad del punto 119: -113.764511\n",
      "Densidad del punto 120: -113.475235\n",
      "Densidad del punto 121: -113.524353\n",
      "Densidad del punto 122: -113.439171\n",
      "Densidad del punto 123: -113.613297\n",
      "Densidad del punto 124: -113.485939\n",
      "Densidad del punto 125: -113.500290\n",
      "Densidad del punto 126: -113.535538\n",
      "Densidad del punto 127: -113.555336\n",
      "Densidad del punto 128: -113.662834\n",
      "Densidad del punto 129: -113.355118\n",
      "Densidad del punto 130: -113.873306\n",
      "Densidad del punto 131: -113.338867\n",
      "Densidad del punto 132: -113.346558\n",
      "Densidad del punto 133: -113.384705\n",
      "Densidad del punto 134: -113.538399\n",
      "Densidad del punto 135: -113.220139\n",
      "Densidad del punto 136: -113.305527\n",
      "Densidad del punto 137: -113.576790\n",
      "Densidad del punto 138: -113.953682\n",
      "Densidad del punto 139: -113.291115\n",
      "Densidad del punto 140: -113.762329\n",
      "Densidad del punto 141: -113.579567\n",
      "Densidad del punto 142: -113.364731\n",
      "Densidad del punto 143: -113.407196\n",
      "Densidad del punto 144: -112.536224\n",
      "Densidad del punto 145: -113.609482\n",
      "Densidad del punto 146: -113.343079\n",
      "Densidad del punto 147: -113.395889\n",
      "Densidad del punto 148: -113.300499\n",
      "Densidad del punto 149: -113.383957\n",
      "Densidad del punto 150: -113.774818\n",
      "Densidad del punto 151: -113.244400\n",
      "Densidad del punto 152: -113.456154\n",
      "Densidad del punto 153: -113.643723\n",
      "Densidad del punto 154: -113.628693\n",
      "Densidad del punto 155: -113.536179\n",
      "Densidad del punto 156: -113.471992\n",
      "Densidad del punto 157: -113.375084\n",
      "Densidad del punto 158: -113.575912\n",
      "Densidad del punto 159: -113.631279\n",
      "Densidad del punto 160: -113.546555\n",
      "Densidad del punto 161: -113.506134\n",
      "Densidad del punto 162: -113.552040\n",
      "Densidad del punto 163: -113.400482\n",
      "Densidad del punto 164: -113.530632\n",
      "Densidad del punto 165: -113.643578\n",
      "Densidad del punto 166: -113.638359\n",
      "Densidad del punto 167: -113.378998\n",
      "Densidad del punto 168: -113.398193\n",
      "Densidad del punto 169: -113.489822\n",
      "Densidad del punto 170: -113.415649\n",
      "Densidad del punto 171: -113.082642\n",
      "Densidad del punto 172: -113.573959\n",
      "Densidad del punto 173: -113.593536\n",
      "Densidad del punto 174: -113.818970\n",
      "Densidad del punto 175: -113.583549\n",
      "Densidad del punto 176: -113.412865\n",
      "Densidad del punto 177: -113.404510\n",
      "Densidad del punto 178: -113.395439\n",
      "Densidad del punto 179: -113.449059\n",
      "Densidad del punto 180: -113.534973\n",
      "Densidad del punto 181: -113.767883\n",
      "Densidad del punto 182: -113.651703\n",
      "Densidad del punto 183: -113.514259\n",
      "Densidad del punto 184: -113.667679\n",
      "Densidad del punto 185: -113.496727\n",
      "Densidad del punto 186: -113.414818\n",
      "Densidad del punto 187: -113.708855\n",
      "Densidad del punto 188: -113.399323\n",
      "Densidad del punto 189: -113.388870\n",
      "Densidad del punto 190: -113.634499\n",
      "Densidad del punto 191: -113.608971\n",
      "Densidad del punto 192: -113.581383\n",
      "Densidad del punto 193: -113.705841\n",
      "Densidad del punto 194: -113.477898\n",
      "Densidad del punto 195: -113.706116\n",
      "Densidad del punto 196: -113.489502\n",
      "Densidad del punto 197: -113.505913\n",
      "Densidad del punto 198: -113.440910\n",
      "Densidad del punto 199: -113.688385\n",
      "Densidad del punto 200: -113.500801\n",
      "Densidad del punto 201: -113.239609\n",
      "Densidad del punto 202: -113.671501\n",
      "Densidad del punto 203: -113.494690\n",
      "Densidad del punto 204: -113.399025\n",
      "Densidad del punto 205: -113.486397\n",
      "Densidad del punto 206: -113.688232\n",
      "Densidad del punto 207: -113.785072\n",
      "Densidad del punto 208: -113.598907\n",
      "Densidad del punto 209: -431981.468750\n",
      "Densidad del punto 210: -398139.593750\n",
      "Densidad del punto 211: -135507.406250\n",
      "Densidad del punto 212: -224947.218750\n",
      "Densidad del punto 213: -340360.343750\n",
      "Densidad del punto 214: -247874.531250\n",
      "Densidad del punto 215: -477563.093750\n",
      "Densidad del punto 216: -1766655.750000\n",
      "Densidad del punto 217: -164423.281250\n",
      "Densidad del punto 218: -743477.125000\n",
      "Densidad del punto 219: -431200.343750\n",
      "Densidad del punto 220: -439858.125000\n",
      "Densidad del punto 221: -231100.734375\n",
      "Densidad del punto 222: -909700.062500\n",
      "Densidad del punto 223: -942782.687500\n",
      "Densidad del punto 224: -358585.937500\n",
      "Densidad del punto 225: -130142.625000\n",
      "Densidad del punto 226: -511773.781250\n",
      "Densidad del punto 227: -718012.937500\n",
      "Densidad del punto 228: -234819.437500\n",
      "Densidad del punto 229: -121732.265625\n",
      "Densidad del punto 230: -111535.585938\n",
      "Densidad del punto 231: -67266.585938\n",
      "Densidad del punto 232: -74840.039062\n",
      "Densidad del punto 233: -253908.703125\n",
      "Densidad del punto 234: -90127.953125\n",
      "Densidad del punto 235: -164152.171875\n",
      "Densidad del punto 236: -69307.914062\n",
      "Densidad del punto 237: -236408.578125\n",
      "Densidad del punto 238: -151685.203125\n",
      "Densidad del punto 239: -110157.437500\n",
      "Densidad del punto 240: -163888.890625\n",
      "Densidad del punto 241: -89561.078125\n",
      "Densidad del punto 242: -115988.406250\n",
      "Densidad del punto 243: -327902.406250\n",
      "Densidad del punto 244: -132109.406250\n",
      "Densidad del punto 245: -216765.812500\n",
      "Densidad del punto 246: -45945.660156\n",
      "Densidad del punto 247: -110046.101562\n",
      "Densidad del punto 248: -116475.937500\n",
      "Densidad del punto 249: -131876.687500\n",
      "Densidad del punto 250: -200648.718750\n",
      "Densidad del punto 251: -638811.875000\n",
      "Densidad del punto 252: -42893.289062\n",
      "Densidad del punto 253: -1349366.875000\n",
      "Densidad del punto 254: -157729.921875\n",
      "Densidad del punto 255: -1434222.250000\n",
      "Densidad del punto 256: -63207.296875\n",
      "Densidad del punto 257: -1767845.875000\n",
      "Densidad del punto 258: -35689.535156\n",
      "Densidad del punto 259: -791373.375000\n",
      "Densidad del punto 260: -892806.875000\n",
      "Densidad del punto 261: -1230399.500000\n",
      "Densidad del punto 262: -1296453.625000\n",
      "Densidad del punto 263: -540239.750000\n",
      "Densidad del punto 264: -692667.375000\n",
      "Densidad del punto 265: -96021.289062\n",
      "Densidad del punto 266: -176456.968750\n",
      "Densidad del punto 267: -516417.406250\n",
      "Densidad del punto 268: -3098211.500000\n",
      "Densidad del punto 269: -224302.937500\n",
      "Densidad del punto 270: -1208721.750000\n",
      "Densidad del punto 271: -706586.125000\n",
      "Densidad del punto 272: -113.430191\n",
      "Densidad del punto 273: -113.690765\n",
      "Densidad del punto 274: -113.492439\n",
      "Densidad del punto 275: -113.423470\n",
      "Densidad del punto 276: -113.547913\n",
      "Densidad del punto 277: -113.579834\n",
      "Densidad del punto 278: -113.568199\n",
      "Densidad del punto 279: -113.482208\n",
      "Densidad del punto 280: -113.660965\n",
      "Densidad del punto 281: -113.955147\n",
      "Densidad del punto 282: -113.453300\n",
      "Densidad del punto 283: -113.499008\n",
      "Densidad del punto 284: -113.688667\n",
      "Densidad del punto 285: -113.596497\n",
      "Densidad del punto 286: -113.616234\n",
      "Densidad del punto 287: -113.625992\n",
      "Densidad del punto 288: -113.436104\n",
      "Densidad del punto 289: -113.519073\n",
      "Densidad del punto 290: -113.491982\n",
      "Densidad del punto 291: -113.670639\n",
      "{268: -3098211.5, 257: -1767845.875, 216: -1766655.75, 255: -1434222.25, 253: -1349366.875, 262: -1296453.625, 261: -1230399.5, 270: -1208721.75, 223: -942782.6875, 222: -909700.0625, 260: -892806.875, 259: -791373.375, 218: -743477.125, 227: -718012.9375, 271: -706586.125, 264: -692667.375, 251: -638811.875, 263: -540239.75, 267: -516417.40625, 226: -511773.78125, 215: -477563.09375, 220: -439858.125, 209: -431981.46875, 219: -431200.34375, 210: -398139.59375, 224: -358585.9375, 213: -340360.34375, 243: -327902.40625, 233: -253908.703125, 214: -247874.53125, 237: -236408.578125, 228: -234819.4375, 221: -231100.734375, 212: -224947.21875, 269: -224302.9375, 245: -216765.8125, 250: -200648.71875, 266: -176456.96875, 217: -164423.28125, 235: -164152.171875, 240: -163888.890625, 254: -157729.921875, 238: -151685.203125, 211: -135507.40625, 244: -132109.40625, 249: -131876.6875, 225: -130142.625, 229: -121732.265625, 248: -116475.9375, 242: -115988.40625, 230: -111535.5859375, 239: -110157.4375, 247: -110046.1015625, 265: -96021.2890625, 234: -90127.953125, 241: -89561.078125, 232: -74840.0390625, 236: -69307.9140625, 231: -67266.5859375, 256: -63207.296875, 246: -45945.66015625, 252: -42893.2890625, 258: -35689.53515625, 281: -113.95514678955078, 138: -113.95368194580078, 106: -113.913818359375, 130: -113.87330627441406, 22: -113.84513854980469, 174: -113.8189697265625, 74: -113.8176498413086, 81: -113.79774475097656, 207: -113.78507232666016, 150: -113.77481842041016, 75: -113.76813507080078, 181: -113.76788330078125, 119: -113.76451110839844, 140: -113.7623291015625, 102: -113.75564575195312, 85: -113.7386245727539, 23: -113.73719024658203, 70: -113.71369934082031, 187: -113.70885467529297, 195: -113.70611572265625, 193: -113.70584106445312, 273: -113.69076538085938, 25: -113.69051361083984, 87: -113.68946838378906, 284: -113.68866729736328, 199: -113.68838500976562, 206: -113.688232421875, 202: -113.67150115966797, 291: -113.67063903808594, 184: -113.66767883300781, 35: -113.66328430175781, 128: -113.66283416748047, 280: -113.66096496582031, 43: -113.65829467773438, 182: -113.65170288085938, 153: -113.64372253417969, 165: -113.6435775756836, 101: -113.64099884033203, 166: -113.63835906982422, 190: -113.6344985961914, 95: -113.63329315185547, 159: -113.63127899169922, 89: -113.62984466552734, 55: -113.6296157836914, 48: -113.62959289550781, 154: -113.62869262695312, 287: -113.62599182128906, 60: -113.61924743652344, 286: -113.6162338256836, 92: -113.61583709716797, 123: -113.61329650878906, 118: -113.61045837402344, 145: -113.60948181152344, 191: -113.60897064208984, 73: -113.60342407226562, 4: -113.6004409790039, 208: -113.59890747070312, 84: -113.59744262695312, 14: -113.59712219238281, 285: -113.59649658203125, 173: -113.59353637695312, 7: -113.5926284790039, 116: -113.59009552001953, 175: -113.58354949951172, 192: -113.58138275146484, 277: -113.579833984375, 141: -113.5795669555664, 137: -113.57678985595703, 158: -113.57591247558594, 172: -113.57395935058594, 69: -113.57307434082031, 278: -113.56819915771484, 112: -113.56776428222656, 34: -113.56671142578125, 24: -113.56277465820312, 40: -113.56006622314453, 127: -113.55533599853516, 59: -113.55523681640625, 162: -113.55204010009766, 276: -113.54791259765625, 160: -113.54655456542969, 134: -113.53839874267578, 2: -113.536865234375, 155: -113.53617858886719, 126: -113.53553771972656, 180: -113.53497314453125, 37: -113.53487396240234, 77: -113.53179168701172, 164: -113.53063201904297, 96: -113.5304183959961, 94: -113.52980041503906, 62: -113.52912139892578, 108: -113.5282211303711, 121: -113.52435302734375, 98: -113.52269744873047, 64: -113.5207290649414, 82: -113.5197525024414, 289: -113.51907348632812, 21: -113.51641845703125, 183: -113.5142593383789, 0: -113.50901794433594, 5: -113.5089340209961, 13: -113.50684356689453, 41: -113.50658416748047, 161: -113.50613403320312, 197: -113.50591278076172, 32: -113.50359344482422, 11: -113.5030746459961, 78: -113.50148010253906, 200: -113.50080108642578, 125: -113.50028991699219, 283: -113.49900817871094, 185: -113.4967269897461, 15: -113.49644470214844, 203: -113.49468994140625, 65: -113.49449157714844, 12: -113.49403381347656, 274: -113.49243927001953, 290: -113.49198150634766, 107: -113.49010467529297, 169: -113.48982238769531, 196: -113.489501953125, 30: -113.48717498779297, 205: -113.48639678955078, 66: -113.48602294921875, 124: -113.4859390258789, 19: -113.48556518554688, 67: -113.48456573486328, 88: -113.48285675048828, 279: -113.48220825195312, 71: -113.48078155517578, 38: -113.47987365722656, 26: -113.47796630859375, 194: -113.47789764404297, 120: -113.47523498535156, 91: -113.4732437133789, 156: -113.47199249267578, 46: -113.46621704101562, 57: -113.4659423828125, 97: -113.46473693847656, 45: -113.46344757080078, 110: -113.46001434326172, 93: -113.45880889892578, 117: -113.45736694335938, 104: -113.45722961425781, 152: -113.4561538696289, 115: -113.45401000976562, 79: -113.45394134521484, 282: -113.45330047607422, 179: -113.44905853271484, 68: -113.44855499267578, 28: -113.44793701171875, 198: -113.44091033935547, 52: -113.44068908691406, 122: -113.43917083740234, 86: -113.43815612792969, 288: -113.43610382080078, 56: -113.43440246582031, 272: -113.43019104003906, 111: -113.42352294921875, 275: -113.42346954345703, 53: -113.4177017211914, 51: -113.41704559326172, 170: -113.4156494140625, 186: -113.4148178100586, 33: -113.41371154785156, 176: -113.4128646850586, 143: -113.40719604492188, 39: -113.40458679199219, 177: -113.40451049804688, 163: -113.40048217773438, 188: -113.39932250976562, 204: -113.3990249633789, 168: -113.398193359375, 147: -113.39588928222656, 178: -113.39543914794922, 44: -113.39053344726562, 189: -113.38887023925781, 3: -113.38642120361328, 133: -113.38470458984375, 149: -113.38395690917969, 113: -113.38097381591797, 167: -113.37899780273438, 109: -113.37689208984375, 157: -113.37508392333984, 83: -113.3697509765625, 142: -113.36473083496094, 105: -113.3641357421875, 29: -113.36029052734375, 8: -113.35971069335938, 9: -113.35919189453125, 1: -113.35848999023438, 129: -113.35511779785156, 132: -113.3465576171875, 17: -113.34622955322266, 61: -113.34370422363281, 146: -113.34307861328125, 72: -113.34037017822266, 131: -113.3388671875, 100: -113.33856964111328, 10: -113.33692169189453, 114: -113.32858276367188, 76: -113.32615661621094, 27: -113.3209228515625, 54: -113.32044982910156, 63: -113.32032775878906, 6: -113.31778717041016, 36: -113.31101989746094, 136: -113.30552673339844, 90: -113.30431365966797, 148: -113.30049896240234, 42: -113.29719543457031, 139: -113.2911148071289, 20: -113.283447265625, 47: -113.27996826171875, 16: -113.26665496826172, 103: -113.25581359863281, 151: -113.24440002441406, 201: -113.23960876464844, 31: -113.2342529296875, 99: -113.22540283203125, 135: -113.22013854980469, 80: -113.19551849365234, 58: -113.1602554321289, 50: -113.15412902832031, 18: -113.12818145751953, 171: -113.0826416015625, 144: -112.53622436523438, 49: -112.46511840820312}\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1], dtype=torch.int32)\n"
     ]
    }
   ],
   "source": [
    "model.print_parameters()\n",
    "model.print_score(X_train)\n",
    "l=model.print_score(X_test)\n",
    "score_ordenado = dict(sorted(l.items(), key=lambda item: item[1]))\n",
    "print(score_ordenado)\n",
    "print(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "05f5127e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Densidad del punto 0: -12.179932\n",
      "Densidad del punto 1: -2.937256\n",
      "Densidad del punto 2: -5.107498\n",
      "Densidad del punto 3: -8.025604\n",
      "Densidad del punto 4: -8.244873\n",
      "Densidad del punto 5: -10.072571\n",
      "Densidad del punto 6: -3.276413\n",
      "Densidad del punto 7: -1.492676\n",
      "Densidad del punto 8: -10.793457\n",
      "Densidad del punto 9: -15.905029\n",
      "Densidad del punto 10: -4.435852\n",
      "Densidad del punto 11: -2.109253\n",
      "Densidad del punto 12: -43.795410\n",
      "Densidad del punto 13: -6.423645\n",
      "Densidad del punto 14: -10.168457\n",
      "Densidad del punto 15: -14.024567\n",
      "Densidad del punto 16: -3.153534\n",
      "Densidad del punto 17: -0.692627\n",
      "Densidad del punto 18: -5.493408\n",
      "Densidad del punto 19: -4.665894\n",
      "Densidad del punto 20: -9.551514\n",
      "Densidad del punto 21: -7.324463\n",
      "Densidad del punto 22: -2.110840\n",
      "Densidad del punto 23: -2.855759\n",
      "Densidad del punto 24: -9.329498\n",
      "Densidad del punto 25: -17.702148\n",
      "Densidad del punto 26: -1.195801\n",
      "Densidad del punto 27: -5.386841\n",
      "Densidad del punto 28: -43.843750\n",
      "Densidad del punto 29: -16.066895\n",
      "Densidad del punto 30: 0.462769\n",
      "Densidad del punto 31: -9.060516\n",
      "Densidad del punto 32: -23.426819\n",
      "Densidad del punto 33: -5.541107\n",
      "Densidad del punto 34: -3.055054\n",
      "Densidad del punto 35: -29.650909\n",
      "Densidad del punto 36: 0.565308\n",
      "Densidad del punto 37: -5.292419\n",
      "Densidad del punto 38: -5.068542\n",
      "Densidad del punto 39: -10.931396\n",
      "Densidad del punto 40: -54.608398\n",
      "Densidad del punto 41: 0.062195\n",
      "Densidad del punto 42: -67.580566\n",
      "Densidad del punto 43: -10.618622\n",
      "Densidad del punto 44: -17.657959\n",
      "Densidad del punto 45: -6.551941\n",
      "Densidad del punto 46: -1.336426\n",
      "Densidad del punto 47: -8.183838\n",
      "Densidad del punto 48: -10.457703\n",
      "Densidad del punto 49: -5.800325\n",
      "Densidad del punto 50: -25.082458\n",
      "Densidad del punto 51: -5.576660\n",
      "Densidad del punto 52: -5.716309\n",
      "Densidad del punto 53: -2.140228\n",
      "Densidad del punto 54: -7.944824\n",
      "Densidad del punto 55: -83.080322\n",
      "Densidad del punto 56: -2.481567\n",
      "Densidad del punto 57: -35.419800\n",
      "Densidad del punto 58: -9.155640\n",
      "Densidad del punto 59: -14.902924\n",
      "Densidad del punto 60: -20.522156\n",
      "Densidad del punto 61: -1.582428\n",
      "Densidad del punto 62: -16.614441\n",
      "Densidad del punto 63: -8.401978\n",
      "Densidad del punto 64: -12.308594\n",
      "Densidad del punto 65: 2.312012\n",
      "Densidad del punto 66: -112.987427\n",
      "Densidad del punto 67: -2.541569\n",
      "Densidad del punto 68: -0.619293\n",
      "Densidad del punto 69: -5.724854\n",
      "Densidad del punto 70: -7.539856\n",
      "Densidad del punto 71: -12.075378\n",
      "Densidad del punto 72: -10.109703\n",
      "Densidad del punto 73: -63.977539\n",
      "Densidad del punto 74: 0.562988\n",
      "Densidad del punto 75: -3.547760\n",
      "Densidad del punto 76: -11.244766\n",
      "Densidad del punto 77: -4.713013\n",
      "Densidad del punto 78: -5.471642\n",
      "Densidad del punto 79: 14.284912\n",
      "Densidad del punto 80: -6.609291\n",
      "Densidad del punto 81: -8.076599\n",
      "Densidad del punto 82: -6.897217\n",
      "Densidad del punto 83: -194.958008\n",
      "Densidad del punto 84: -3.094971\n",
      "Densidad del punto 85: -35.577881\n",
      "Densidad del punto 86: -17.486694\n",
      "Densidad del punto 87: -1.668396\n",
      "Densidad del punto 88: -19.565521\n",
      "Densidad del punto 89: -5.696777\n",
      "Densidad del punto 90: -29.584900\n",
      "Densidad del punto 91: -3.216187\n",
      "Densidad del punto 92: -43.056519\n",
      "Densidad del punto 93: -3.651489\n",
      "Densidad del punto 94: -6.338974\n",
      "Densidad del punto 95: -9.859741\n",
      "Densidad del punto 96: -28.947144\n",
      "Densidad del punto 97: -5.209579\n",
      "Densidad del punto 98: -7.520508\n",
      "Densidad del punto 99: -1.212219\n",
      "Densidad del punto 100: -4.914490\n",
      "Densidad del punto 101: -1.269531\n",
      "Densidad del punto 102: -8.081985\n",
      "Densidad del punto 103: -1.161865\n",
      "Densidad del punto 104: -24.671387\n",
      "Densidad del punto 105: -22.839569\n",
      "Densidad del punto 106: 1.357422\n",
      "Densidad del punto 107: -4.472794\n",
      "Densidad del punto 108: -8.172058\n",
      "Densidad del punto 109: -18.822998\n",
      "Densidad del punto 110: 5.033203\n",
      "Densidad del punto 111: -1.533447\n",
      "Densidad del punto 112: -1.642181\n",
      "Densidad del punto 113: -13.506653\n",
      "Densidad del punto 114: -18.949463\n",
      "Densidad del punto 115: -1.250122\n",
      "Densidad del punto 116: -14.143311\n",
      "Densidad del punto 117: -10.716354\n",
      "Densidad del punto 118: -80.313599\n",
      "Densidad del punto 119: -9.409424\n",
      "Densidad del punto 120: -51.295654\n",
      "Densidad del punto 121: -149.337891\n",
      "Densidad del punto 122: -1.147461\n",
      "Densidad del punto 123: -10.642380\n",
      "Densidad del punto 124: -2.927124\n",
      "Densidad del punto 125: -3.769470\n",
      "Densidad del punto 126: -20.857056\n",
      "Densidad del punto 127: -4.180908\n",
      "Densidad del punto 128: -3.729126\n",
      "Densidad del punto 129: -8.003841\n",
      "Densidad del punto 130: 7.995117\n",
      "Densidad del punto 131: -3.051147\n",
      "Densidad del punto 132: -5.166107\n",
      "Densidad del punto 133: -3.317627\n",
      "Densidad del punto 134: -12.077148\n",
      "Densidad del punto 135: -4.490417\n",
      "Densidad del punto 136: -7.327621\n",
      "Densidad del punto 137: -57.665039\n",
      "Densidad del punto 138: -17.956848\n",
      "Densidad del punto 139: -1.737976\n",
      "Densidad del punto 140: -32.191956\n",
      "Densidad del punto 141: -0.742310\n",
      "Densidad del punto 142: -10.188232\n",
      "Densidad del punto 143: -8.728027\n",
      "Densidad del punto 144: -10.807564\n",
      "Densidad del punto 145: -3.795410\n",
      "Densidad del punto 146: -8.478516\n",
      "Densidad del punto 147: -14.859009\n",
      "Densidad del punto 148: -23.173950\n",
      "Densidad del punto 149: -3.839447\n",
      "Densidad del punto 150: -7.925964\n",
      "Densidad del punto 151: -9.648682\n",
      "Densidad del punto 152: -5.830200\n",
      "Densidad del punto 153: -13.482864\n",
      "Densidad del punto 154: -27.715942\n",
      "Densidad del punto 155: -3.491211\n",
      "Densidad del punto 156: -33.949036\n",
      "Densidad del punto 157: -1.284363\n",
      "Densidad del punto 158: -26.912476\n",
      "Densidad del punto 159: -5.710571\n",
      "Densidad del punto 160: -13.901001\n",
      "Densidad del punto 161: -3.790283\n",
      "Densidad del punto 162: -1.899902\n",
      "Densidad del punto 163: 8.611572\n",
      "Densidad del punto 164: -35.835938\n",
      "Densidad del punto 165: -3.890747\n",
      "Densidad del punto 166: -0.704773\n",
      "Densidad del punto 167: 0.007324\n",
      "Densidad del punto 168: -26.497498\n",
      "Densidad del punto 169: -11.497559\n",
      "Densidad del punto 170: -12.297211\n",
      "Densidad del punto 171: -3.794617\n",
      "Densidad del punto 172: -22.947021\n",
      "Densidad del punto 173: -5.478943\n",
      "Densidad del punto 174: 10.102539\n",
      "Densidad del punto 175: -4.981091\n",
      "Densidad del punto 176: 10.342041\n",
      "Densidad del punto 177: -12.383362\n",
      "Densidad del punto 178: -25.672241\n",
      "Densidad del punto 179: -9.718445\n",
      "Densidad del punto 180: -0.136475\n",
      "Densidad del punto 181: -6.064682\n",
      "Densidad del punto 182: -3.747803\n",
      "Densidad del punto 183: -9.236427\n",
      "Densidad del punto 184: -8.061646\n",
      "Densidad del punto 185: -3.375626\n",
      "Densidad del punto 186: 2.349365\n",
      "Densidad del punto 187: -3.594284\n",
      "Densidad del punto 188: -1.050446\n",
      "Densidad del punto 189: -5.241501\n",
      "Densidad del punto 190: -6.256165\n",
      "Densidad del punto 191: -12.190979\n",
      "Densidad del punto 192: -11.229126\n",
      "Densidad del punto 193: -9.256683\n",
      "Densidad del punto 194: 0.279053\n",
      "Densidad del punto 195: -27.053894\n",
      "Densidad del punto 196: -8.486160\n",
      "Densidad del punto 197: -43.082703\n",
      "Densidad del punto 198: -3.635178\n",
      "Densidad del punto 199: -6.298706\n",
      "Densidad del punto 200: -1.268616\n",
      "Densidad del punto 201: -10.605560\n",
      "Densidad del punto 202: -11.949829\n",
      "Densidad del punto 203: -3.162689\n",
      "Densidad del punto 204: -3.230591\n",
      "Densidad del punto 205: -9.931641\n",
      "Densidad del punto 206: -5.293106\n",
      "Densidad del punto 207: -3.630569\n",
      "Densidad del punto 208: -40.026855\n",
      "Densidad del punto 209: 10.283203\n",
      "Densidad del punto 210: -24.708008\n",
      "Densidad del punto 211: -10.441528\n",
      "Densidad del punto 212: -55.493652\n",
      "Densidad del punto 213: -34.019043\n",
      "Densidad del punto 214: -77.739258\n",
      "Densidad del punto 215: -70.993896\n",
      "Densidad del punto 216: -10391.703125\n",
      "Densidad del punto 217: -14.977966\n",
      "Densidad del punto 218: -110.833496\n",
      "Densidad del punto 219: -1671886.625000\n",
      "Densidad del punto 220: -130.044189\n",
      "Densidad del punto 221: 1924.125000\n",
      "Densidad del punto 222: -22.024902\n",
      "Densidad del punto 223: -68.235077\n",
      "Densidad del punto 224: -9.746094\n",
      "Densidad del punto 225: -14.911133\n",
      "Densidad del punto 226: -101.185852\n",
      "Densidad del punto 227: -487.566406\n",
      "Densidad del punto 228: 9.492188\n",
      "Densidad del punto 229: -155.795044\n",
      "Densidad del punto 230: -5.485352\n",
      "Densidad del punto 231: -2.346436\n",
      "Densidad del punto 232: -6.554077\n",
      "Densidad del punto 233: -7.320557\n",
      "Densidad del punto 234: -7.572998\n",
      "Densidad del punto 235: -517.992188\n",
      "Densidad del punto 236: -3.368164\n",
      "Densidad del punto 237: -103.170410\n",
      "Densidad del punto 238: -213.436523\n",
      "Densidad del punto 239: -34.994385\n",
      "Densidad del punto 240: -37.344604\n",
      "Densidad del punto 241: -23.852905\n",
      "Densidad del punto 242: -16.617676\n",
      "Densidad del punto 243: -9271.156250\n",
      "Densidad del punto 244: -56.000000\n",
      "Densidad del punto 245: -896.299316\n",
      "Densidad del punto 246: -9.552979\n",
      "Densidad del punto 247: -1.948486\n",
      "Densidad del punto 248: -57.228760\n",
      "Densidad del punto 249: -4.505371\n",
      "Densidad del punto 250: -1.673218\n",
      "Densidad del punto 251: -53.861816\n",
      "Densidad del punto 252: -6.264648\n",
      "Densidad del punto 253: -324.503906\n",
      "Densidad del punto 254: -24.189270\n",
      "Densidad del punto 255: -220.385406\n",
      "Densidad del punto 256: -7.845459\n",
      "Densidad del punto 257: -43.917969\n",
      "Densidad del punto 258: -84.097900\n",
      "Densidad del punto 259: 54928.500000\n",
      "Densidad del punto 260: -40.453125\n",
      "Densidad del punto 261: -1380984.000000\n",
      "Densidad del punto 262: -12.127045\n",
      "Densidad del punto 263: 107194.000000\n",
      "Densidad del punto 264: 1018962.000000\n",
      "Densidad del punto 265: -147.462891\n",
      "Densidad del punto 266: -174.533203\n",
      "Densidad del punto 267: -59.109375\n",
      "Densidad del punto 268: 15451.250000\n",
      "Densidad del punto 269: -32.421875\n",
      "Densidad del punto 270: -65.868652\n",
      "Densidad del punto 271: -31.331360\n",
      "Densidad del punto 272: -43.712646\n",
      "Densidad del punto 273: -24.701660\n",
      "Densidad del punto 274: -10.902710\n",
      "Densidad del punto 275: -20.486938\n",
      "Densidad del punto 276: -30.787109\n",
      "Densidad del punto 277: -3.894022\n",
      "Densidad del punto 278: -2.185242\n",
      "Densidad del punto 279: -14.340210\n",
      "Densidad del punto 280: -23.179626\n",
      "Densidad del punto 281: -15.094650\n",
      "Densidad del punto 282: -70.411743\n",
      "Densidad del punto 283: -0.300690\n",
      "Densidad del punto 284: -0.028320\n",
      "Densidad del punto 285: -17.551895\n",
      "Densidad del punto 286: -9.918427\n",
      "Densidad del punto 287: -44.955444\n",
      "Densidad del punto 288: -17.186157\n",
      "Densidad del punto 289: -10.215561\n",
      "Densidad del punto 290: -15.263054\n",
      "Densidad del punto 291: -2.982994\n",
      "🔍 SCORES de anomalías (label == 1):\n",
      "Índice 209 | Score: 10.2832 | Predicción: 0\n",
      "Índice 210 | Score: -24.7080 | Predicción: 1\n",
      "Índice 211 | Score: -10.4415 | Predicción: 1\n",
      "Índice 212 | Score: -55.4937 | Predicción: 1\n",
      "Índice 213 | Score: -34.0190 | Predicción: 1\n",
      "Índice 214 | Score: -77.7393 | Predicción: 1\n",
      "Índice 215 | Score: -70.9939 | Predicción: 1\n",
      "Índice 216 | Score: -10391.7031 | Predicción: 1\n",
      "Índice 217 | Score: -14.9780 | Predicción: 1\n",
      "Índice 218 | Score: -110.8335 | Predicción: 1\n",
      "Índice 219 | Score: -1671886.6250 | Predicción: 1\n",
      "Índice 220 | Score: -130.0442 | Predicción: 1\n",
      "Índice 221 | Score: 1924.1250 | Predicción: 0\n",
      "Índice 222 | Score: -22.0249 | Predicción: 1\n",
      "Índice 223 | Score: -68.2351 | Predicción: 1\n",
      "Índice 224 | Score: -9.7461 | Predicción: 1\n",
      "Índice 225 | Score: -14.9111 | Predicción: 1\n",
      "Índice 226 | Score: -101.1859 | Predicción: 1\n",
      "Índice 227 | Score: -487.5664 | Predicción: 1\n",
      "Índice 228 | Score: 9.4922 | Predicción: 0\n",
      "Índice 229 | Score: -155.7950 | Predicción: 1\n",
      "Índice 230 | Score: -5.4854 | Predicción: 0\n",
      "Índice 231 | Score: -2.3464 | Predicción: 0\n",
      "Índice 232 | Score: -6.5541 | Predicción: 0\n",
      "Índice 233 | Score: -7.3206 | Predicción: 0\n",
      "Índice 234 | Score: -7.5730 | Predicción: 0\n",
      "Índice 235 | Score: -517.9922 | Predicción: 1\n",
      "Índice 236 | Score: -3.3682 | Predicción: 0\n",
      "Índice 237 | Score: -103.1704 | Predicción: 1\n",
      "Índice 238 | Score: -213.4365 | Predicción: 1\n",
      "Índice 239 | Score: -34.9944 | Predicción: 1\n",
      "Índice 240 | Score: -37.3446 | Predicción: 1\n",
      "Índice 241 | Score: -23.8529 | Predicción: 1\n",
      "Índice 242 | Score: -16.6177 | Predicción: 1\n",
      "Índice 243 | Score: -9271.1562 | Predicción: 1\n",
      "Índice 244 | Score: -56.0000 | Predicción: 1\n",
      "Índice 245 | Score: -896.2993 | Predicción: 1\n",
      "Índice 246 | Score: -9.5530 | Predicción: 1\n",
      "Índice 247 | Score: -1.9485 | Predicción: 0\n",
      "Índice 248 | Score: -57.2288 | Predicción: 1\n",
      "Índice 249 | Score: -4.5054 | Predicción: 0\n",
      "Índice 250 | Score: -1.6732 | Predicción: 0\n",
      "Índice 251 | Score: -53.8618 | Predicción: 1\n",
      "Índice 252 | Score: -6.2646 | Predicción: 0\n",
      "Índice 253 | Score: -324.5039 | Predicción: 1\n",
      "Índice 254 | Score: -24.1893 | Predicción: 1\n",
      "Índice 255 | Score: -220.3854 | Predicción: 1\n",
      "Índice 256 | Score: -7.8455 | Predicción: 0\n",
      "Índice 257 | Score: -43.9180 | Predicción: 1\n",
      "Índice 258 | Score: -84.0979 | Predicción: 1\n",
      "Índice 259 | Score: 54928.5000 | Predicción: 0\n",
      "Índice 260 | Score: -40.4531 | Predicción: 1\n",
      "Índice 261 | Score: -1380984.0000 | Predicción: 1\n",
      "Índice 262 | Score: -12.1270 | Predicción: 1\n",
      "Índice 263 | Score: 107194.0000 | Predicción: 0\n",
      "Índice 264 | Score: 1018962.0000 | Predicción: 0\n",
      "Índice 265 | Score: -147.4629 | Predicción: 1\n",
      "Índice 266 | Score: -174.5332 | Predicción: 1\n",
      "Índice 267 | Score: -59.1094 | Predicción: 1\n",
      "Índice 268 | Score: 15451.2500 | Predicción: 0\n",
      "Índice 269 | Score: -32.4219 | Predicción: 1\n",
      "Índice 270 | Score: -65.8687 | Predicción: 1\n",
      "Índice 271 | Score: -31.3314 | Predicción: 1\n"
     ]
    }
   ],
   "source": [
    "# Obtener todos los scores como diccionario {i: score}\n",
    "score_dict = model.print_score(X_test)\n",
    "\n",
    "# Filtrar solo los scores de los ejemplos anómalos (label == 1)\n",
    "scores_anomalos = {\n",
    "    i: score\n",
    "    for i, score in score_dict.items()\n",
    "    if true_labels[i] == 1\n",
    "}\n",
    "\n",
    "# Mostrar\n",
    "print(\"🔍 SCORES de anomalías (label == 1):\")\n",
    "for i, score in scores_anomalos.items():\n",
    "    print(f\"Índice {i} | Score: {score:.4f} | Predicción: {preds[i].item()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbc7d665",
   "metadata": {},
   "source": [
    "NUEVO METODO ANTONIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "ff06db24",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ZScoreThreshold:\n",
    "    def fit(self, X):\n",
    "        \"\"\"\n",
    "        Calcula media y desviación estándar por columna.\n",
    "        X: tensor (n_samples, n_features)\n",
    "        \"\"\"\n",
    "        self.mu = X.mean(dim=0)\n",
    "        self.std = X.std(dim=0)\n",
    "        self.std[self.std == 0] = 1e-6  # evita divisiones por cero\n",
    "\n",
    "    def score(self, X):\n",
    "        \"\"\"\n",
    "        Retorna el número de columnas fuera de lo normal por muestra.\n",
    "        \"\"\"\n",
    "        z_scores = (X - self.mu) / self.std\n",
    "        return (z_scores.abs() > 1.96).sum(dim=1)  # puedes parametrizar el umbral\n",
    "\n",
    "    def predict(self, X, num_columns=1):\n",
    "        \"\"\"\n",
    "        Marca como anomalía si más de x columnas estan fuera del estandar.\n",
    "        \"\"\"\n",
    "\n",
    "        scores = self.score(X)\n",
    "        return (scores > num_columns).int()\n",
    "    # Puedes ajustar el número de columnas según lo que consideres anómalo\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "cda9473b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([292])\n",
      "Ejemplo 0: Predicción = 0, Etiqueta real = 0\n",
      "Ejemplo 1: Predicción = 0, Etiqueta real = 0\n",
      "Ejemplo 2: Predicción = 0, Etiqueta real = 0\n",
      "Ejemplo 3: Predicción = 0, Etiqueta real = 0\n",
      "Ejemplo 4: Predicción = 0, Etiqueta real = 0\n",
      "Ejemplo 5: Predicción = 0, Etiqueta real = 0\n",
      "Ejemplo 6: Predicción = 0, Etiqueta real = 0\n",
      "Ejemplo 7: Predicción = 0, Etiqueta real = 0\n",
      "Ejemplo 8: Predicción = 0, Etiqueta real = 0\n",
      "Ejemplo 9: Predicción = 0, Etiqueta real = 0\n",
      "Ejemplo 10: Predicción = 0, Etiqueta real = 0\n",
      "Ejemplo 11: Predicción = 0, Etiqueta real = 0\n",
      "Ejemplo 12: Predicción = 1, Etiqueta real = 0\n",
      "Ejemplo 13: Predicción = 0, Etiqueta real = 0\n",
      "Ejemplo 14: Predicción = 0, Etiqueta real = 0\n",
      "Ejemplo 15: Predicción = 0, Etiqueta real = 0\n",
      "Ejemplo 16: Predicción = 0, Etiqueta real = 0\n",
      "Ejemplo 17: Predicción = 0, Etiqueta real = 0\n",
      "Ejemplo 18: Predicción = 0, Etiqueta real = 0\n",
      "Ejemplo 19: Predicción = 0, Etiqueta real = 0\n",
      "Ejemplo 20: Predicción = 0, Etiqueta real = 0\n",
      "Ejemplo 21: Predicción = 0, Etiqueta real = 0\n",
      "Ejemplo 22: Predicción = 0, Etiqueta real = 0\n",
      "Ejemplo 23: Predicción = 0, Etiqueta real = 0\n",
      "Ejemplo 24: Predicción = 0, Etiqueta real = 0\n",
      "Ejemplo 25: Predicción = 0, Etiqueta real = 0\n",
      "Ejemplo 26: Predicción = 0, Etiqueta real = 0\n",
      "Ejemplo 27: Predicción = 0, Etiqueta real = 0\n",
      "Ejemplo 28: Predicción = 1, Etiqueta real = 0\n",
      "Ejemplo 29: Predicción = 0, Etiqueta real = 0\n",
      "Ejemplo 30: Predicción = 0, Etiqueta real = 0\n",
      "Ejemplo 31: Predicción = 0, Etiqueta real = 0\n",
      "Ejemplo 32: Predicción = 0, Etiqueta real = 0\n",
      "Ejemplo 33: Predicción = 0, Etiqueta real = 0\n",
      "Ejemplo 34: Predicción = 0, Etiqueta real = 0\n",
      "Ejemplo 35: Predicción = 1, Etiqueta real = 0\n",
      "Ejemplo 36: Predicción = 0, Etiqueta real = 0\n",
      "Ejemplo 37: Predicción = 0, Etiqueta real = 0\n",
      "Ejemplo 38: Predicción = 0, Etiqueta real = 0\n",
      "Ejemplo 39: Predicción = 0, Etiqueta real = 0\n",
      "Ejemplo 40: Predicción = 1, Etiqueta real = 0\n",
      "Ejemplo 41: Predicción = 0, Etiqueta real = 0\n",
      "Ejemplo 42: Predicción = 1, Etiqueta real = 0\n",
      "Ejemplo 43: Predicción = 0, Etiqueta real = 0\n",
      "Ejemplo 44: Predicción = 0, Etiqueta real = 0\n",
      "Ejemplo 45: Predicción = 0, Etiqueta real = 0\n",
      "Ejemplo 46: Predicción = 0, Etiqueta real = 0\n",
      "Ejemplo 47: Predicción = 0, Etiqueta real = 0\n",
      "Ejemplo 48: Predicción = 0, Etiqueta real = 0\n",
      "Ejemplo 49: Predicción = 0, Etiqueta real = 0\n",
      "Ejemplo 50: Predicción = 0, Etiqueta real = 0\n",
      "Ejemplo 51: Predicción = 0, Etiqueta real = 0\n",
      "Ejemplo 52: Predicción = 0, Etiqueta real = 0\n",
      "Ejemplo 53: Predicción = 0, Etiqueta real = 0\n",
      "Ejemplo 54: Predicción = 0, Etiqueta real = 0\n",
      "Ejemplo 55: Predicción = 1, Etiqueta real = 0\n",
      "Ejemplo 56: Predicción = 0, Etiqueta real = 0\n",
      "Ejemplo 57: Predicción = 0, Etiqueta real = 0\n",
      "Ejemplo 58: Predicción = 0, Etiqueta real = 0\n",
      "Ejemplo 59: Predicción = 0, Etiqueta real = 0\n",
      "Ejemplo 60: Predicción = 0, Etiqueta real = 0\n",
      "Ejemplo 61: Predicción = 0, Etiqueta real = 0\n",
      "Ejemplo 62: Predicción = 0, Etiqueta real = 0\n",
      "Ejemplo 63: Predicción = 0, Etiqueta real = 0\n",
      "Ejemplo 64: Predicción = 0, Etiqueta real = 0\n",
      "Ejemplo 65: Predicción = 0, Etiqueta real = 0\n",
      "Ejemplo 66: Predicción = 1, Etiqueta real = 0\n",
      "Ejemplo 67: Predicción = 0, Etiqueta real = 0\n",
      "Ejemplo 68: Predicción = 0, Etiqueta real = 0\n",
      "Ejemplo 69: Predicción = 0, Etiqueta real = 0\n",
      "Ejemplo 70: Predicción = 0, Etiqueta real = 0\n",
      "Ejemplo 71: Predicción = 0, Etiqueta real = 0\n",
      "Ejemplo 72: Predicción = 0, Etiqueta real = 0\n",
      "Ejemplo 73: Predicción = 1, Etiqueta real = 0\n",
      "Ejemplo 74: Predicción = 0, Etiqueta real = 0\n",
      "Ejemplo 75: Predicción = 0, Etiqueta real = 0\n",
      "Ejemplo 76: Predicción = 0, Etiqueta real = 0\n",
      "Ejemplo 77: Predicción = 0, Etiqueta real = 0\n",
      "Ejemplo 78: Predicción = 0, Etiqueta real = 0\n",
      "Ejemplo 79: Predicción = 0, Etiqueta real = 0\n",
      "Ejemplo 80: Predicción = 0, Etiqueta real = 0\n",
      "Ejemplo 81: Predicción = 0, Etiqueta real = 0\n",
      "Ejemplo 82: Predicción = 0, Etiqueta real = 0\n",
      "Ejemplo 83: Predicción = 1, Etiqueta real = 0\n",
      "Ejemplo 84: Predicción = 1, Etiqueta real = 0\n",
      "Ejemplo 85: Predicción = 1, Etiqueta real = 0\n",
      "Ejemplo 86: Predicción = 0, Etiqueta real = 0\n",
      "Ejemplo 87: Predicción = 0, Etiqueta real = 0\n",
      "Ejemplo 88: Predicción = 1, Etiqueta real = 0\n",
      "Ejemplo 89: Predicción = 1, Etiqueta real = 0\n",
      "Ejemplo 90: Predicción = 0, Etiqueta real = 0\n",
      "Ejemplo 91: Predicción = 0, Etiqueta real = 0\n",
      "Ejemplo 92: Predicción = 1, Etiqueta real = 0\n",
      "Ejemplo 93: Predicción = 0, Etiqueta real = 0\n",
      "Ejemplo 94: Predicción = 0, Etiqueta real = 0\n",
      "Ejemplo 95: Predicción = 0, Etiqueta real = 0\n",
      "Ejemplo 96: Predicción = 0, Etiqueta real = 0\n",
      "Ejemplo 97: Predicción = 0, Etiqueta real = 0\n",
      "Ejemplo 98: Predicción = 0, Etiqueta real = 0\n",
      "Ejemplo 99: Predicción = 0, Etiqueta real = 0\n",
      "Ejemplo 100: Predicción = 0, Etiqueta real = 0\n",
      "Ejemplo 101: Predicción = 0, Etiqueta real = 0\n",
      "Ejemplo 102: Predicción = 0, Etiqueta real = 0\n",
      "Ejemplo 103: Predicción = 0, Etiqueta real = 0\n",
      "Ejemplo 104: Predicción = 1, Etiqueta real = 0\n",
      "Ejemplo 105: Predicción = 1, Etiqueta real = 0\n",
      "Ejemplo 106: Predicción = 0, Etiqueta real = 0\n",
      "Ejemplo 107: Predicción = 0, Etiqueta real = 0\n",
      "Ejemplo 108: Predicción = 0, Etiqueta real = 0\n",
      "Ejemplo 109: Predicción = 0, Etiqueta real = 0\n",
      "Ejemplo 110: Predicción = 1, Etiqueta real = 0\n",
      "Ejemplo 111: Predicción = 0, Etiqueta real = 0\n",
      "Ejemplo 112: Predicción = 0, Etiqueta real = 0\n",
      "Ejemplo 113: Predicción = 0, Etiqueta real = 0\n",
      "Ejemplo 114: Predicción = 0, Etiqueta real = 0\n",
      "Ejemplo 115: Predicción = 0, Etiqueta real = 0\n",
      "Ejemplo 116: Predicción = 0, Etiqueta real = 0\n",
      "Ejemplo 117: Predicción = 0, Etiqueta real = 0\n",
      "Ejemplo 118: Predicción = 1, Etiqueta real = 0\n",
      "Ejemplo 119: Predicción = 1, Etiqueta real = 0\n",
      "Ejemplo 120: Predicción = 1, Etiqueta real = 0\n",
      "Ejemplo 121: Predicción = 1, Etiqueta real = 0\n",
      "Ejemplo 122: Predicción = 0, Etiqueta real = 0\n",
      "Ejemplo 123: Predicción = 0, Etiqueta real = 0\n",
      "Ejemplo 124: Predicción = 0, Etiqueta real = 0\n",
      "Ejemplo 125: Predicción = 0, Etiqueta real = 0\n",
      "Ejemplo 126: Predicción = 1, Etiqueta real = 0\n",
      "Ejemplo 127: Predicción = 0, Etiqueta real = 0\n",
      "Ejemplo 128: Predicción = 0, Etiqueta real = 0\n",
      "Ejemplo 129: Predicción = 0, Etiqueta real = 0\n",
      "Ejemplo 130: Predicción = 0, Etiqueta real = 0\n",
      "Ejemplo 131: Predicción = 0, Etiqueta real = 0\n",
      "Ejemplo 132: Predicción = 0, Etiqueta real = 0\n",
      "Ejemplo 133: Predicción = 0, Etiqueta real = 0\n",
      "Ejemplo 134: Predicción = 0, Etiqueta real = 0\n",
      "Ejemplo 135: Predicción = 0, Etiqueta real = 0\n",
      "Ejemplo 136: Predicción = 0, Etiqueta real = 0\n",
      "Ejemplo 137: Predicción = 1, Etiqueta real = 0\n",
      "Ejemplo 138: Predicción = 0, Etiqueta real = 0\n",
      "Ejemplo 139: Predicción = 0, Etiqueta real = 0\n",
      "Ejemplo 140: Predicción = 0, Etiqueta real = 0\n",
      "Ejemplo 141: Predicción = 0, Etiqueta real = 0\n",
      "Ejemplo 142: Predicción = 0, Etiqueta real = 0\n",
      "Ejemplo 143: Predicción = 0, Etiqueta real = 0\n",
      "Ejemplo 144: Predicción = 0, Etiqueta real = 0\n",
      "Ejemplo 145: Predicción = 0, Etiqueta real = 0\n",
      "Ejemplo 146: Predicción = 0, Etiqueta real = 0\n",
      "Ejemplo 147: Predicción = 0, Etiqueta real = 0\n",
      "Ejemplo 148: Predicción = 0, Etiqueta real = 0\n",
      "Ejemplo 149: Predicción = 0, Etiqueta real = 0\n",
      "Ejemplo 150: Predicción = 0, Etiqueta real = 0\n",
      "Ejemplo 151: Predicción = 0, Etiqueta real = 0\n",
      "Ejemplo 152: Predicción = 0, Etiqueta real = 0\n",
      "Ejemplo 153: Predicción = 0, Etiqueta real = 0\n",
      "Ejemplo 154: Predicción = 1, Etiqueta real = 0\n",
      "Ejemplo 155: Predicción = 0, Etiqueta real = 0\n",
      "Ejemplo 156: Predicción = 0, Etiqueta real = 0\n",
      "Ejemplo 157: Predicción = 0, Etiqueta real = 0\n",
      "Ejemplo 158: Predicción = 0, Etiqueta real = 0\n",
      "Ejemplo 159: Predicción = 0, Etiqueta real = 0\n",
      "Ejemplo 160: Predicción = 0, Etiqueta real = 0\n",
      "Ejemplo 161: Predicción = 0, Etiqueta real = 0\n",
      "Ejemplo 162: Predicción = 0, Etiqueta real = 0\n",
      "Ejemplo 163: Predicción = 0, Etiqueta real = 0\n",
      "Ejemplo 164: Predicción = 1, Etiqueta real = 0\n",
      "Ejemplo 165: Predicción = 0, Etiqueta real = 0\n",
      "Ejemplo 166: Predicción = 0, Etiqueta real = 0\n",
      "Ejemplo 167: Predicción = 0, Etiqueta real = 0\n",
      "Ejemplo 168: Predicción = 0, Etiqueta real = 0\n",
      "Ejemplo 169: Predicción = 0, Etiqueta real = 0\n",
      "Ejemplo 170: Predicción = 0, Etiqueta real = 0\n",
      "Ejemplo 171: Predicción = 0, Etiqueta real = 0\n",
      "Ejemplo 172: Predicción = 0, Etiqueta real = 0\n",
      "Ejemplo 173: Predicción = 0, Etiqueta real = 0\n",
      "Ejemplo 174: Predicción = 0, Etiqueta real = 0\n",
      "Ejemplo 175: Predicción = 0, Etiqueta real = 0\n",
      "Ejemplo 176: Predicción = 0, Etiqueta real = 0\n",
      "Ejemplo 177: Predicción = 0, Etiqueta real = 0\n",
      "Ejemplo 178: Predicción = 0, Etiqueta real = 0\n",
      "Ejemplo 179: Predicción = 0, Etiqueta real = 0\n",
      "Ejemplo 180: Predicción = 0, Etiqueta real = 0\n",
      "Ejemplo 181: Predicción = 0, Etiqueta real = 0\n",
      "Ejemplo 182: Predicción = 0, Etiqueta real = 0\n",
      "Ejemplo 183: Predicción = 0, Etiqueta real = 0\n",
      "Ejemplo 184: Predicción = 0, Etiqueta real = 0\n",
      "Ejemplo 185: Predicción = 0, Etiqueta real = 0\n",
      "Ejemplo 186: Predicción = 0, Etiqueta real = 0\n",
      "Ejemplo 187: Predicción = 0, Etiqueta real = 0\n",
      "Ejemplo 188: Predicción = 0, Etiqueta real = 0\n",
      "Ejemplo 189: Predicción = 0, Etiqueta real = 0\n",
      "Ejemplo 190: Predicción = 0, Etiqueta real = 0\n",
      "Ejemplo 191: Predicción = 0, Etiqueta real = 0\n",
      "Ejemplo 192: Predicción = 0, Etiqueta real = 0\n",
      "Ejemplo 193: Predicción = 0, Etiqueta real = 0\n",
      "Ejemplo 194: Predicción = 0, Etiqueta real = 0\n",
      "Ejemplo 195: Predicción = 0, Etiqueta real = 0\n",
      "Ejemplo 196: Predicción = 0, Etiqueta real = 0\n",
      "Ejemplo 197: Predicción = 0, Etiqueta real = 0\n",
      "Ejemplo 198: Predicción = 0, Etiqueta real = 0\n",
      "Ejemplo 199: Predicción = 0, Etiqueta real = 0\n",
      "Ejemplo 200: Predicción = 0, Etiqueta real = 0\n",
      "Ejemplo 201: Predicción = 0, Etiqueta real = 0\n",
      "Ejemplo 202: Predicción = 0, Etiqueta real = 0\n",
      "Ejemplo 203: Predicción = 0, Etiqueta real = 0\n",
      "Ejemplo 204: Predicción = 0, Etiqueta real = 0\n",
      "Ejemplo 205: Predicción = 0, Etiqueta real = 0\n",
      "Ejemplo 206: Predicción = 0, Etiqueta real = 0\n",
      "Ejemplo 207: Predicción = 0, Etiqueta real = 0\n",
      "Ejemplo 208: Predicción = 1, Etiqueta real = 0\n",
      "Ejemplo 209: Predicción = 1, Etiqueta real = 1\n",
      "Ejemplo 210: Predicción = 1, Etiqueta real = 1\n",
      "Ejemplo 211: Predicción = 0, Etiqueta real = 1\n",
      "Ejemplo 212: Predicción = 1, Etiqueta real = 1\n",
      "Ejemplo 213: Predicción = 0, Etiqueta real = 1\n",
      "Ejemplo 214: Predicción = 1, Etiqueta real = 1\n",
      "Ejemplo 215: Predicción = 1, Etiqueta real = 1\n",
      "Ejemplo 216: Predicción = 1, Etiqueta real = 1\n",
      "Ejemplo 217: Predicción = 0, Etiqueta real = 1\n",
      "Ejemplo 218: Predicción = 1, Etiqueta real = 1\n",
      "Ejemplo 219: Predicción = 1, Etiqueta real = 1\n",
      "Ejemplo 220: Predicción = 1, Etiqueta real = 1\n",
      "Ejemplo 221: Predicción = 1, Etiqueta real = 1\n",
      "Ejemplo 222: Predicción = 0, Etiqueta real = 1\n",
      "Ejemplo 223: Predicción = 0, Etiqueta real = 1\n",
      "Ejemplo 224: Predicción = 1, Etiqueta real = 1\n",
      "Ejemplo 225: Predicción = 1, Etiqueta real = 1\n",
      "Ejemplo 226: Predicción = 1, Etiqueta real = 1\n",
      "Ejemplo 227: Predicción = 1, Etiqueta real = 1\n",
      "Ejemplo 228: Predicción = 1, Etiqueta real = 1\n",
      "Ejemplo 229: Predicción = 1, Etiqueta real = 1\n",
      "Ejemplo 230: Predicción = 0, Etiqueta real = 1\n",
      "Ejemplo 231: Predicción = 0, Etiqueta real = 1\n",
      "Ejemplo 232: Predicción = 0, Etiqueta real = 1\n",
      "Ejemplo 233: Predicción = 0, Etiqueta real = 1\n",
      "Ejemplo 234: Predicción = 1, Etiqueta real = 1\n",
      "Ejemplo 235: Predicción = 1, Etiqueta real = 1\n",
      "Ejemplo 236: Predicción = 1, Etiqueta real = 1\n",
      "Ejemplo 237: Predicción = 1, Etiqueta real = 1\n",
      "Ejemplo 238: Predicción = 1, Etiqueta real = 1\n",
      "Ejemplo 239: Predicción = 0, Etiqueta real = 1\n",
      "Ejemplo 240: Predicción = 1, Etiqueta real = 1\n",
      "Ejemplo 241: Predicción = 0, Etiqueta real = 1\n",
      "Ejemplo 242: Predicción = 0, Etiqueta real = 1\n",
      "Ejemplo 243: Predicción = 1, Etiqueta real = 1\n",
      "Ejemplo 244: Predicción = 1, Etiqueta real = 1\n",
      "Ejemplo 245: Predicción = 1, Etiqueta real = 1\n",
      "Ejemplo 246: Predicción = 0, Etiqueta real = 1\n",
      "Ejemplo 247: Predicción = 0, Etiqueta real = 1\n",
      "Ejemplo 248: Predicción = 1, Etiqueta real = 1\n",
      "Ejemplo 249: Predicción = 1, Etiqueta real = 1\n",
      "Ejemplo 250: Predicción = 0, Etiqueta real = 1\n",
      "Ejemplo 251: Predicción = 1, Etiqueta real = 1\n",
      "Ejemplo 252: Predicción = 0, Etiqueta real = 1\n",
      "Ejemplo 253: Predicción = 1, Etiqueta real = 1\n",
      "Ejemplo 254: Predicción = 0, Etiqueta real = 1\n",
      "Ejemplo 255: Predicción = 1, Etiqueta real = 1\n",
      "Ejemplo 256: Predicción = 0, Etiqueta real = 1\n",
      "Ejemplo 257: Predicción = 1, Etiqueta real = 1\n",
      "Ejemplo 258: Predicción = 1, Etiqueta real = 1\n",
      "Ejemplo 259: Predicción = 1, Etiqueta real = 1\n",
      "Ejemplo 260: Predicción = 1, Etiqueta real = 1\n",
      "Ejemplo 261: Predicción = 1, Etiqueta real = 1\n",
      "Ejemplo 262: Predicción = 0, Etiqueta real = 1\n",
      "Ejemplo 263: Predicción = 1, Etiqueta real = 1\n",
      "Ejemplo 264: Predicción = 1, Etiqueta real = 1\n",
      "Ejemplo 265: Predicción = 1, Etiqueta real = 1\n",
      "Ejemplo 266: Predicción = 1, Etiqueta real = 1\n",
      "Ejemplo 267: Predicción = 1, Etiqueta real = 1\n",
      "Ejemplo 268: Predicción = 1, Etiqueta real = 1\n",
      "Ejemplo 269: Predicción = 1, Etiqueta real = 1\n",
      "Ejemplo 270: Predicción = 1, Etiqueta real = 1\n",
      "Ejemplo 271: Predicción = 0, Etiqueta real = 1\n",
      "Ejemplo 272: Predicción = 1, Etiqueta real = 0\n",
      "Ejemplo 273: Predicción = 1, Etiqueta real = 0\n",
      "Ejemplo 274: Predicción = 0, Etiqueta real = 0\n",
      "Ejemplo 275: Predicción = 0, Etiqueta real = 0\n",
      "Ejemplo 276: Predicción = 0, Etiqueta real = 0\n",
      "Ejemplo 277: Predicción = 0, Etiqueta real = 0\n",
      "Ejemplo 278: Predicción = 0, Etiqueta real = 0\n",
      "Ejemplo 279: Predicción = 0, Etiqueta real = 0\n",
      "Ejemplo 280: Predicción = 1, Etiqueta real = 0\n",
      "Ejemplo 281: Predicción = 0, Etiqueta real = 0\n",
      "Ejemplo 282: Predicción = 1, Etiqueta real = 0\n",
      "Ejemplo 283: Predicción = 0, Etiqueta real = 0\n",
      "Ejemplo 284: Predicción = 1, Etiqueta real = 0\n",
      "Ejemplo 285: Predicción = 0, Etiqueta real = 0\n",
      "Ejemplo 286: Predicción = 0, Etiqueta real = 0\n",
      "Ejemplo 287: Predicción = 1, Etiqueta real = 0\n",
      "Ejemplo 288: Predicción = 0, Etiqueta real = 0\n",
      "Ejemplo 289: Predicción = 0, Etiqueta real = 0\n",
      "Ejemplo 290: Predicción = 0, Etiqueta real = 0\n",
      "Ejemplo 291: Predicción = 0, Etiqueta real = 0\n",
      "Accuracy: 0.821917808219178\n",
      "F1 Score: 0.7532982387729902\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score,f1_score\n",
    "file_path = \"dataset_embeddings_encoder_resnet.csv\"\n",
    "\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "df_normal = df[df['label'] == 0]\n",
    "embedding_columns = df.columns[:-1]  # nombres de columnas excepto la última\n",
    "embeddings_train = df_normal[embedding_columns].values\n",
    "model = ZScoreThreshold()\n",
    "X_train = torch.tensor(embeddings_train, dtype=torch.float32)\n",
    "\n",
    "model.fit(X_train)\n",
    "\n",
    "\n",
    "embeddings = df[embedding_columns].values\n",
    "X_test = torch.tensor(embeddings, dtype=torch.float32)\n",
    "\n",
    "\n",
    "preds = model.predict(X_test, num_columns=8)     #PARA LOS EMBEDDINGS DEL PREENTRENADO 300,350,400 ESTA BIEN, 200, 180 MUY BIEN\n",
    "print(preds.shape)                               #PARA LOS EMBEDDINGS DEL AUTOENCODER 2,3\n",
    "                                                 #PARA LOS EMBEDDINGS DEL AUTOENCODER RESNET 15,12,10,13,14,11\n",
    "\n",
    "# Paso 3: imprimir por pantalla (predicción y etiqueta real)\n",
    "for i, (p, real) in enumerate(zip(preds, df[\"label\"])):\n",
    "    print(f\"Ejemplo {i}: Predicción = {p.item()}, Etiqueta real = {real}\")\n",
    "\n",
    "true_labels = df[\"label\"]\n",
    "acc= accuracy_score(true_labels, preds)\n",
    "f1 = f1_score(true_labels, preds, average='macro')  \n",
    "print(\"Accuracy:\", acc)\n",
    "print(\"F1 Score:\", f1)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
